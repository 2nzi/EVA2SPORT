{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ea9663-0253-4c2e-8564-cd9c6ca9cab3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25ea9663-0253-4c2e-8564-cd9c6ca9cab3",
    "outputId": "5bec4b63-ea31-450b-cc5c-ec6d4491900a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18m8Zu0M2zZuaeUIIfoKCZ_N9M7cylxIB\n",
      "From (redirected): https://drive.google.com/uc?id=18m8Zu0M2zZuaeUIIfoKCZ_N9M7cylxIB&confirm=t&uuid=5f36322e-6dd0-4bf9-9a20-a4c6fc2d41d1\n",
      "To: /content/FIFA.zip\n",
      "100% 1.41G/1.41G [00:06<00:00, 204MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gdown\n",
    "\n",
    "import os\n",
    "\n",
    "# CrÃ©er un dossier pour stocker les donnÃ©es\n",
    "os.makedirs(\"/workspace/data\", exist_ok=True)\n",
    "\n",
    "# TÃ©lÃ©charger le ZIP dans ce dossier\n",
    "!gdown --id 18m8Zu0M2zZuaeUIIfoKCZ_N9M7cylxIB -O /workspace/FIFA.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75234fb6-04a5-4efa-a5d9-eb61172c52d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75234fb6-04a5-4efa-a5d9-eb61172c52d3",
    "outputId": "ecdb3e57-4617-4d1c-f957-93406d4feb84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FIFA.zip extrait avec succÃ¨s dans /content/data\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"/workspace/FIFA.zip\"\n",
    "extract_path = \"/workspace/data\"\n",
    "\n",
    "# Extraction\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"âœ… FIFA.zip extrait avec succÃ¨s dans\", extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca9279e-48fa-4a38-9851-402a6bd43442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dca9279e-48fa-4a38-9851-402a6bd43442",
    "outputId": "9138ffe1-00a5-4a76-baf9-3af0c4e3d363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sam2' already exists and is not an empty directory.\n",
      "/content/sam2\n",
      "Obtaining file:///content/sam2\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
      "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.3.2)\n",
      "Requirement already satisfied: iopath>=0.1.10 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.1.10)\n",
      "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.2.1)\n",
      "Requirement already satisfied: black==24.2.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (24.2.0)\n",
      "Requirement already satisfied: usort==1.0.2 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.0.2)\n",
      "Requirement already satisfied: ufmt==2.0.0b2 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.0b2)\n",
      "Requirement already satisfied: fvcore>=0.1.5.post20221221 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.1.5.post20221221)\n",
      "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.2.2)\n",
      "Requirement already satisfied: scikit-image>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.25.2)\n",
      "Requirement already satisfied: tensorboard>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.18.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.8 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.8)\n",
      "Requirement already satisfied: tensordict>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.11.0.86)\n",
      "Requirement already satisfied: submitit>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.5.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black==24.2.0->SAM-2==1.0) (8.1.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black==24.2.0->SAM-2==1.0) (1.1.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from black==24.2.0->SAM-2==1.0) (24.2)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black==24.2.0->SAM-2==1.0) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black==24.2.0->SAM-2==1.0) (4.3.8)\n",
      "Requirement already satisfied: libcst>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from ufmt==2.0.0b2->SAM-2==1.0) (1.7.0)\n",
      "Requirement already satisfied: moreorless>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from ufmt==2.0.0b2->SAM-2==1.0) (0.5.0)\n",
      "Requirement already satisfied: tomlkit>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from ufmt==2.0.0b2->SAM-2==1.0) (0.13.2)\n",
      "Requirement already satisfied: trailrunner>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from ufmt==2.0.0b2->SAM-2==1.0) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from ufmt==2.0.0b2->SAM-2==1.0) (4.13.2)\n",
      "Requirement already satisfied: attrs>=21.2.0 in /usr/local/lib/python3.11/dist-packages (from usort==1.0.2->SAM-2==1.0) (25.3.0)\n",
      "Requirement already satisfied: stdlibs>=2021.4.1 in /usr/local/lib/python3.11/dist-packages (from usort==1.0.2->SAM-2==1.0) (2025.5.10)\n",
      "Requirement already satisfied: toml>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from usort==1.0.2->SAM-2==1.0) (0.10.2)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore>=0.1.5.post20221221->SAM-2==1.0) (0.1.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore>=0.1.5.post20221221->SAM-2==1.0) (6.0.2)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore>=0.1.5.post20221221->SAM-2==1.0) (3.1.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore>=0.1.5.post20221221->SAM-2==1.0) (0.9.0)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->SAM-2==1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->SAM-2==1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->SAM-2==1.0) (2025.2)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools>=2.0.8->SAM-2==1.0) (3.10.0)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.24.0->SAM-2==1.0) (1.15.3)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.24.0->SAM-2==1.0) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.24.0->SAM-2==1.0) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.24.0->SAM-2==1.0) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.24.0->SAM-2==1.0) (0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit>=1.5.1->SAM-2==1.0) (3.1.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (1.71.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (3.8)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (5.29.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.17.0->SAM-2==1.0) (3.1.3)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.6.0->SAM-2==1.0) (8.7.0)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.6.0->SAM-2==1.0) (3.10.18)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.8->SAM-2==1.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.8->SAM-2==1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.8->SAM-2==1.0) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.8->SAM-2==1.0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.8->SAM-2==1.0) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.17.0->SAM-2==1.0) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->tensordict>=0.6.0->SAM-2==1.0) (3.21.0)\n",
      "Building wheels for collected packages: SAM-2\n",
      "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for SAM-2: filename=sam_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13851 sha256=db5935216c709465f23225c6c0c5eb016cc5862c6e8b97b9155df56fac3e6f03\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3043iyt4/wheels/76/dc/37/006d341f6080de50c00d031747ee8a1a03f3fb513175bce1c0\n",
      "Successfully built SAM-2\n",
      "Installing collected packages: SAM-2\n",
      "  Attempting uninstall: SAM-2\n",
      "    Found existing installation: SAM-2 1.0\n",
      "    Uninstalling SAM-2-1.0:\n",
      "      Successfully uninstalled SAM-2-1.0\n",
      "Successfully installed SAM-2-1.0\n",
      "Downloading sam2.1_hiera_tiny.pt checkpoint...\n",
      "--2025-05-14 13:54:21--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_tiny.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.121, 108.157.254.102, 108.157.254.124, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156008466 (149M) [application/vnd.snesdev-page-table]\n",
      "Saving to: â€˜sam2.1_hiera_tiny.pt.1â€™\n",
      "\n",
      "sam2.1_hiera_tiny.p 100%[===================>] 148.78M   283MB/s    in 0.5s    \n",
      "\n",
      "2025-05-14 13:54:22 (283 MB/s) - â€˜sam2.1_hiera_tiny.pt.1â€™ saved [156008466/156008466]\n",
      "\n",
      "Downloading sam2.1_hiera_small.pt checkpoint...\n",
      "--2025-05-14 13:54:22--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.121, 108.157.254.102, 108.157.254.124, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 184416285 (176M) [application/vnd.snesdev-page-table]\n",
      "Saving to: â€˜sam2.1_hiera_small.pt.1â€™\n",
      "\n",
      "sam2.1_hiera_small. 100%[===================>] 175.87M   234MB/s    in 0.8s    \n",
      "\n",
      "2025-05-14 13:54:22 (234 MB/s) - â€˜sam2.1_hiera_small.pt.1â€™ saved [184416285/184416285]\n",
      "\n",
      "Downloading sam2.1_hiera_base_plus.pt checkpoint...\n",
      "--2025-05-14 13:54:22--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.121, 108.157.254.102, 108.157.254.124, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 323606802 (309M) [application/vnd.snesdev-page-table]\n",
      "Saving to: â€˜sam2.1_hiera_base_plus.pt.1â€™\n",
      "\n",
      "sam2.1_hiera_base_p 100%[===================>] 308.62M   315MB/s    in 1.0s    \n",
      "\n",
      "2025-05-14 13:54:23 (315 MB/s) - â€˜sam2.1_hiera_base_plus.pt.1â€™ saved [323606802/323606802]\n",
      "\n",
      "Downloading sam2.1_hiera_large.pt checkpoint...\n",
      "--2025-05-14 13:54:23--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.121, 108.157.254.102, 108.157.254.124, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.121|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 898083611 (856M) [application/vnd.snesdev-page-table]\n",
      "Saving to: â€˜sam2.1_hiera_large.pt.1â€™\n",
      "\n",
      "sam2.1_hiera_large. 100%[===================>] 856.48M   267MB/s    in 3.2s    \n",
      "\n",
      "2025-05-14 13:54:27 (264 MB/s) - â€˜sam2.1_hiera_large.pt.1â€™ saved [898083611/898083611]\n",
      "\n",
      "All checkpoints are downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# âœ… 3. Cloner le repo SAM2 et installer les dÃ©pendances\n",
    "!git clone https://github.com/facebookresearch/sam2.git\n",
    "%cd sam2\n",
    "!pip install -e \".[dev]\"\n",
    "\n",
    "# âœ… 4. TÃ©lÃ©charger les checkpoints\n",
    "os.chdir(\"checkpoints\")\n",
    "!./download_ckpts.sh\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae73811-c4d2-467d-a6d3-7a38a359e101",
   "metadata": {
    "id": "2ae73811-c4d2-467d-a6d3-7a38a359e101"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# âœ… 5. Modifier le fichier YAML de configuration\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(\"sam2\")\n",
    "\n",
    "yaml_path = Path(\"configs/sam2.1_training/sam2.1_hiera_b+_MOSE_finetune.yaml\")\n",
    "with open(yaml_path, 'r') as f:\n",
    "    config = OmegaConf.load(f)\n",
    "\n",
    "img_folder = \"/workspace/data/JPEGImages\"\n",
    "gt_folder = \"/workspace/data/BinaryMasks\"\n",
    "log_dir = \"/workspace/logs\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b38574c-8118-41d4-9989-5104ea1eed07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b38574c-8118-41d4-9989-5104ea1eed07",
    "outputId": "431f4cb3-313f-4cff-93dc-ef15ceadb47a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YAML mis Ã  jour avec les chemins RunPod\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config.dataset.img_folder = img_folder\n",
    "config.dataset.gt_folder = gt_folder\n",
    "config.dataset.file_list_txt = None\n",
    "config.dataset.multiple = 1\n",
    "\n",
    "config.scratch.resolution = 1024\n",
    "config.scratch.num_frames = 4\n",
    "\n",
    "config.launcher.gpus_per_node = 1\n",
    "config.trainer.checkpoint.save_freq = 5\n",
    "config.launcher.experiment_log_dir = log_dir\n",
    "\n",
    "# âœ… Sauvegarder la nouvelle configuration\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(OmegaConf.to_yaml(config))\n",
    "\n",
    "print(\"âœ… YAML mis Ã  jour avec les chemins RunPod\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fOrzk85zH6fm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOrzk85zH6fm",
    "outputId": "d09609fc-6c1b-4cfd-b9a9-2aa84b70dc14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/sam2\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/sam2/\n",
    "!touch /workspace/sam2/sam2/configs/sam2.1_training/__init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "q1O8rUobICcm",
   "metadata": {
    "id": "q1O8rUobICcm"
   },
   "outputs": [],
   "source": [
    "# ðŸ”§ Remplacer compose() par un chargement direct dans train.py\n",
    "!sed -i 's/cfg = compose(config_name=args.config)/cfg = OmegaConf.load(args.config)/' /workspace/sam2/training/train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec8f6efc-f97c-468d-bcc2-6f67b9a475ba",
   "metadata": {
    "id": "ec8f6efc-f97c-468d-bcc2-6f67b9a475ba"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()              # Forcer la libÃ©ration CPU\n",
    "torch.cuda.empty_cache()  # Nettoyer CUDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hSV0GGXeIMOs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSV0GGXeIMOs",
    "outputId": "e6e09073-d5b0-4dc8-9d91-fed86881e025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/sam2\n",
      "###################### Train App Config ####################\n",
      "scratch:\n",
      "  resolution: 1024\n",
      "  train_batch_size: 1\n",
      "  num_train_workers: 10\n",
      "  num_frames: 4\n",
      "  max_num_objects: 3\n",
      "  base_lr: 5.0e-06\n",
      "  vision_lr: 3.0e-06\n",
      "  phases_per_epoch: 1\n",
      "  num_epochs: 40\n",
      "dataset:\n",
      "  img_folder: /content/data/JPEGImages\n",
      "  gt_folder: /content/data/BinaryMasks\n",
      "  file_list_txt: null\n",
      "  multiplier: 2\n",
      "  multiple: 1\n",
      "vos:\n",
      "  train_transforms:\n",
      "  - _target_: training.dataset.transforms.ComposeAPI\n",
      "    transforms:\n",
      "    - _target_: training.dataset.transforms.RandomHorizontalFlip\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.RandomAffine\n",
      "      degrees: 25\n",
      "      shear: 20\n",
      "      image_interpolation: bilinear\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.RandomResizeAPI\n",
      "      sizes: ${scratch.resolution}\n",
      "      square: true\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.ColorJitter\n",
      "      consistent_transform: true\n",
      "      brightness: 0.1\n",
      "      contrast: 0.03\n",
      "      saturation: 0.03\n",
      "      hue: null\n",
      "    - _target_: training.dataset.transforms.RandomGrayscale\n",
      "      p: 0.05\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.ColorJitter\n",
      "      consistent_transform: false\n",
      "      brightness: 0.1\n",
      "      contrast: 0.05\n",
      "      saturation: 0.05\n",
      "      hue: null\n",
      "    - _target_: training.dataset.transforms.ToTensorAPI\n",
      "    - _target_: training.dataset.transforms.NormalizeAPI\n",
      "      mean:\n",
      "      - 0.485\n",
      "      - 0.456\n",
      "      - 0.406\n",
      "      std:\n",
      "      - 0.229\n",
      "      - 0.224\n",
      "      - 0.225\n",
      "trainer:\n",
      "  _target_: training.trainer.Trainer\n",
      "  mode: train_only\n",
      "  max_epochs: ${times:${scratch.num_epochs},${scratch.phases_per_epoch}}\n",
      "  accelerator: cuda\n",
      "  seed_value: 123\n",
      "  model:\n",
      "    _target_: training.model.sam2.SAM2Train\n",
      "    image_encoder:\n",
      "      _target_: sam2.modeling.backbones.image_encoder.ImageEncoder\n",
      "      scalp: 1\n",
      "      trunk:\n",
      "        _target_: sam2.modeling.backbones.hieradet.Hiera\n",
      "        embed_dim: 112\n",
      "        num_heads: 2\n",
      "        drop_path_rate: 0.1\n",
      "      neck:\n",
      "        _target_: sam2.modeling.backbones.image_encoder.FpnNeck\n",
      "        position_encoding:\n",
      "          _target_: sam2.modeling.position_encoding.PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          normalize: true\n",
      "          scale: null\n",
      "          temperature: 10000\n",
      "        d_model: 256\n",
      "        backbone_channel_list:\n",
      "        - 896\n",
      "        - 448\n",
      "        - 224\n",
      "        - 112\n",
      "        fpn_top_down_levels:\n",
      "        - 2\n",
      "        - 3\n",
      "        fpn_interp_model: nearest\n",
      "    memory_attention:\n",
      "      _target_: sam2.modeling.memory_attention.MemoryAttention\n",
      "      d_model: 256\n",
      "      pos_enc_at_input: true\n",
      "      layer:\n",
      "        _target_: sam2.modeling.memory_attention.MemoryAttentionLayer\n",
      "        activation: relu\n",
      "        dim_feedforward: 2048\n",
      "        dropout: 0.1\n",
      "        pos_enc_at_attn: false\n",
      "        self_attention:\n",
      "          _target_: sam2.modeling.sam.transformer.RoPEAttention\n",
      "          rope_theta: 10000.0\n",
      "          feat_sizes:\n",
      "          - 64\n",
      "          - 64\n",
      "          embedding_dim: 256\n",
      "          num_heads: 1\n",
      "          downsample_rate: 1\n",
      "          dropout: 0.1\n",
      "        d_model: 256\n",
      "        pos_enc_at_cross_attn_keys: true\n",
      "        pos_enc_at_cross_attn_queries: false\n",
      "        cross_attention:\n",
      "          _target_: sam2.modeling.sam.transformer.RoPEAttention\n",
      "          rope_theta: 10000.0\n",
      "          feat_sizes:\n",
      "          - 64\n",
      "          - 64\n",
      "          rope_k_repeat: true\n",
      "          embedding_dim: 256\n",
      "          num_heads: 1\n",
      "          downsample_rate: 1\n",
      "          dropout: 0.1\n",
      "          kv_in_dim: 64\n",
      "      num_layers: 4\n",
      "    memory_encoder:\n",
      "      _target_: sam2.modeling.memory_encoder.MemoryEncoder\n",
      "      out_dim: 64\n",
      "      position_encoding:\n",
      "        _target_: sam2.modeling.position_encoding.PositionEmbeddingSine\n",
      "        num_pos_feats: 64\n",
      "        normalize: true\n",
      "        scale: null\n",
      "        temperature: 10000\n",
      "      mask_downsampler:\n",
      "        _target_: sam2.modeling.memory_encoder.MaskDownSampler\n",
      "        kernel_size: 3\n",
      "        stride: 2\n",
      "        padding: 1\n",
      "      fuser:\n",
      "        _target_: sam2.modeling.memory_encoder.Fuser\n",
      "        layer:\n",
      "          _target_: sam2.modeling.memory_encoder.CXBlock\n",
      "          dim: 256\n",
      "          kernel_size: 7\n",
      "          padding: 3\n",
      "          layer_scale_init_value: 1.0e-06\n",
      "          use_dwconv: true\n",
      "        num_layers: 2\n",
      "    num_maskmem: 7\n",
      "    image_size: ${scratch.resolution}\n",
      "    sigmoid_scale_for_mem_enc: 20.0\n",
      "    sigmoid_bias_for_mem_enc: -10.0\n",
      "    use_mask_input_as_output_without_sam: true\n",
      "    directly_add_no_mem_embed: true\n",
      "    no_obj_embed_spatial: true\n",
      "    use_high_res_features_in_sam: true\n",
      "    multimask_output_in_sam: true\n",
      "    iou_prediction_use_sigmoid: true\n",
      "    use_obj_ptrs_in_encoder: true\n",
      "    add_tpos_enc_to_obj_ptrs: true\n",
      "    proj_tpos_enc_in_obj_ptrs: true\n",
      "    use_signed_tpos_enc_to_obj_ptrs: true\n",
      "    only_obj_ptrs_in_the_past_for_eval: true\n",
      "    pred_obj_scores: true\n",
      "    pred_obj_scores_mlp: true\n",
      "    fixed_no_obj_ptr: true\n",
      "    multimask_output_for_tracking: true\n",
      "    use_multimask_token_for_obj_ptr: true\n",
      "    multimask_min_pt_num: 0\n",
      "    multimask_max_pt_num: 1\n",
      "    use_mlp_for_obj_ptr_proj: true\n",
      "    prob_to_use_pt_input_for_train: 0.5\n",
      "    prob_to_use_pt_input_for_eval: 0.0\n",
      "    prob_to_use_box_input_for_train: 0.5\n",
      "    prob_to_use_box_input_for_eval: 0.0\n",
      "    prob_to_sample_from_gt_for_train: 0.1\n",
      "    num_frames_to_correct_for_train: 2\n",
      "    num_frames_to_correct_for_eval: 1\n",
      "    rand_frames_to_correct_for_train: true\n",
      "    add_all_frames_to_correct_as_cond: true\n",
      "    num_init_cond_frames_for_train: 2\n",
      "    rand_init_cond_frames_for_train: true\n",
      "    num_correction_pt_per_frame: 7\n",
      "    use_act_ckpt_iterative_pt_sampling: false\n",
      "    num_init_cond_frames_for_eval: 1\n",
      "    forward_backbone_per_frame_for_eval: true\n",
      "  data:\n",
      "    train:\n",
      "      _target_: training.dataset.sam2_datasets.TorchTrainMixedDataset\n",
      "      phases_per_epoch: ${scratch.phases_per_epoch}\n",
      "      batch_sizes:\n",
      "      - ${scratch.train_batch_size}\n",
      "      datasets:\n",
      "      - _target_: training.dataset.utils.RepeatFactorWrapper\n",
      "        dataset:\n",
      "          _target_: training.dataset.utils.ConcatDataset\n",
      "          datasets:\n",
      "          - _target_: training.dataset.vos_dataset.VOSDataset\n",
      "            transforms: ${vos.train_transforms}\n",
      "            training: true\n",
      "            video_dataset:\n",
      "              _target_: training.dataset.vos_raw_dataset.PNGRawDataset\n",
      "              img_folder: ${dataset.img_folder}\n",
      "              gt_folder: ${dataset.gt_folder}\n",
      "              file_list_txt: ${dataset.file_list_txt}\n",
      "            sampler:\n",
      "              _target_: training.dataset.vos_sampler.RandomUniformSampler\n",
      "              num_frames: ${scratch.num_frames}\n",
      "              max_num_objects: ${scratch.max_num_objects}\n",
      "            multiplier: ${dataset.multiplier}\n",
      "      shuffle: true\n",
      "      num_workers: ${scratch.num_train_workers}\n",
      "      pin_memory: true\n",
      "      drop_last: true\n",
      "      collate_fn:\n",
      "        _target_: training.utils.data_utils.collate_fn\n",
      "        _partial_: true\n",
      "        dict_key: all\n",
      "  optim:\n",
      "    amp:\n",
      "      enabled: true\n",
      "      amp_dtype: bfloat16\n",
      "    optimizer:\n",
      "      _target_: torch.optim.AdamW\n",
      "    gradient_clip:\n",
      "      _target_: training.optimizer.GradientClipper\n",
      "      max_norm: 0.1\n",
      "      norm_type: 2\n",
      "    param_group_modifiers:\n",
      "    - _target_: training.optimizer.layer_decay_param_modifier\n",
      "      _partial_: true\n",
      "      layer_decay_value: 0.9\n",
      "      apply_to: image_encoder.trunk\n",
      "      overrides:\n",
      "      - pattern: '*pos_embed*'\n",
      "        value: 1.0\n",
      "    options:\n",
      "      lr:\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.CosineParamScheduler\n",
      "          start_value: ${scratch.base_lr}\n",
      "          end_value: ${divide:${scratch.base_lr},10}\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.CosineParamScheduler\n",
      "          start_value: ${scratch.vision_lr}\n",
      "          end_value: ${divide:${scratch.vision_lr},10}\n",
      "        param_names:\n",
      "        - image_encoder.*\n",
      "      weight_decay:\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.ConstantParamScheduler\n",
      "          value: 0.1\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.ConstantParamScheduler\n",
      "          value: 0.0\n",
      "        param_names:\n",
      "        - '*bias*'\n",
      "        module_cls_names:\n",
      "        - torch.nn.LayerNorm\n",
      "  loss:\n",
      "    all:\n",
      "      _target_: training.loss_fns.MultiStepMultiMasksAndIous\n",
      "      weight_dict:\n",
      "        loss_mask: 20\n",
      "        loss_dice: 1\n",
      "        loss_iou: 1\n",
      "        loss_class: 1\n",
      "      supervise_all_iou: true\n",
      "      iou_use_l1_loss: true\n",
      "      pred_obj_scores: true\n",
      "      focal_gamma_obj_score: 0.0\n",
      "      focal_alpha_obj_score: -1.0\n",
      "  distributed:\n",
      "    backend: nccl\n",
      "    find_unused_parameters: true\n",
      "  logging:\n",
      "    tensorboard_writer:\n",
      "      _target_: training.utils.logger.make_tensorboard_logger\n",
      "      log_dir: ${launcher.experiment_log_dir}/tensorboard\n",
      "      flush_secs: 120\n",
      "      should_log: true\n",
      "    log_dir: ${launcher.experiment_log_dir}/logs\n",
      "    log_freq: 10\n",
      "  checkpoint:\n",
      "    save_dir: ${launcher.experiment_log_dir}/checkpoints\n",
      "    save_freq: 5\n",
      "    model_weight_initializer:\n",
      "      _partial_: true\n",
      "      _target_: training.utils.checkpoint_utils.load_state_dict_into_model\n",
      "      strict: true\n",
      "      ignore_unexpected_keys: null\n",
      "      ignore_missing_keys: null\n",
      "      state_dict:\n",
      "        _target_: training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels\n",
      "        checkpoint_path: ./checkpoints/sam2.1_hiera_base_plus.pt\n",
      "        ckpt_state_dict_keys:\n",
      "        - model\n",
      "launcher:\n",
      "  num_nodes: 1\n",
      "  gpus_per_node: 1\n",
      "  experiment_log_dir: /content/logs\n",
      "submitit:\n",
      "  partition: null\n",
      "  account: null\n",
      "  qos: null\n",
      "  cpus_per_task: 10\n",
      "  use_cluster: false\n",
      "  timeout_hour: 24\n",
      "  name: null\n",
      "  port_range:\n",
      "  - 10000\n",
      "  - 65000\n",
      "\n",
      "############################################################\n",
      "2025-05-14 14:09:20.532331: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-14 14:09:20.549753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747231760.570934   10108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747231760.577443   10108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-14 14:09:20.598468: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO 2025-05-14 14:09:24,378 train_utils.py: 108: MACHINE SEED: 4920\n",
      "INFO 2025-05-14 14:09:24,380 train_utils.py: 154: Logging ENV_VARIABLES\n",
      "INFO 2025-05-14 14:09:24,380 train_utils.py: 155: CGROUP_MEMORY_EVENTS=/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events\n",
      "CLICOLOR=1\n",
      "CLOUDSDK_CONFIG=/content/.config\n",
      "CLOUDSDK_PYTHON=python3\n",
      "COLAB_BACKEND_VERSION=next\n",
      "COLAB_DEBUG_ADAPTER_MUX_PATH=/usr/local/bin/dap_multiplexer\n",
      "COLAB_FILE_HANDLER_ADDR=localhost:3453\n",
      "COLAB_GPU=1\n",
      "COLAB_JUPYTER_IP=172.28.0.12\n",
      "COLAB_JUPYTER_TOKEN=\n",
      "COLAB_JUPYTER_TRANSPORT=ipc\n",
      "COLAB_KERNEL_MANAGER_PROXY_HOST=172.28.0.12\n",
      "COLAB_KERNEL_MANAGER_PROXY_PORT=6000\n",
      "COLAB_LANGUAGE_SERVER_PROXY=/usr/colab/bin/language_service\n",
      "COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS=/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages\n",
      "COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT=30s\n",
      "COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL=http://172.28.0.1:8013/\n",
      "COLAB_RELEASE_TAG=release-colab_20250512-060057_RC00\n",
      "COLAB_TPU_1VM=\n",
      "COLAB_WARMUP_DEFAULTS=1\n",
      "CUDA_MODULE_LOADING=LAZY\n",
      "CUDA_VERSION=12.5.1\n",
      "DEBIAN_FRONTEND=noninteractive\n",
      "ENABLE_RUNTIME_UPTIME_TELEMETRY=1\n",
      "ENV=/root/.bashrc\n",
      "GCE_METADATA_TIMEOUT=3\n",
      "GCS_READ_CACHE_BLOCK_SIZE_MB=16\n",
      "GIT_PAGER=cat\n",
      "HOME=/root\n",
      "HOSTNAME=34f1b8ef304f\n",
      "HYDRA_FULL_ERROR=1\n",
      "JPY_PARENT_PID=131\n",
      "KMP_DUPLICATE_LIB_OK=True\n",
      "KMP_EXTRA_ARGS=--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-l4-s-33g96m9zq9mi5 --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true \n",
      "KMP_INIT_AT_FORK=FALSE\n",
      "KMP_LISTEN_PORT=6000\n",
      "KMP_TARGET_PORT=9000\n",
      "LANG=en_US.UTF-8\n",
      "LANGUAGE=en_US\n",
      "LAST_FORCED_REBUILD=20250424\n",
      "LC_ALL=en_US.UTF-8\n",
      "LD_LIBRARY_PATH=/usr/local/lib/python3.11/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
      "LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n",
      "LOCAL_RANK=0\n",
      "MASTER_ADDR=localhost\n",
      "MASTER_PORT=41851\n",
      "MODEL_PROXY_BASE_URL=https://mp.kaggle.net/models/openapi\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "NCCL_VERSION=2.22.3-1\n",
      "NO_GCE_CHECK=False\n",
      "NVARCH=x86_64\n",
      "NVIDIA_DRIVER_CAPABILITIES=compute,utility\n",
      "NVIDIA_PRODUCT_NAME=CUDA\n",
      "NVIDIA_REQUIRE_CUDA=cuda>=12.5 brand=unknown,driver>=470,driver<471 brand=grid,driver>=470,driver<471 brand=tesla,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=vapps,driver>=470,driver<471 brand=vpc,driver>=470,driver<471 brand=vcs,driver>=470,driver<471 brand=vws,driver>=470,driver<471 brand=cloudgaming,driver>=470,driver<471 brand=unknown,driver>=535,driver<536 brand=grid,driver>=535,driver<536 brand=tesla,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=vapps,driver>=535,driver<536 brand=vpc,driver>=535,driver<536 brand=vcs,driver>=535,driver<536 brand=vws,driver>=535,driver<536 brand=cloudgaming,driver>=535,driver<536 brand=unknown,driver>=550,driver<551 brand=grid,driver>=550,driver<551 brand=tesla,driver>=550,driver<551 brand=nvidia,driver>=550,driver<551 brand=quadro,driver>=550,driver<551 brand=quadrortx,driver>=550,driver<551 brand=nvidiartx,driver>=550,driver<551 brand=vapps,driver>=550,driver<551 brand=vpc,driver>=550,driver<551 brand=vcs,driver>=550,driver<551 brand=vws,driver>=550,driver<551 brand=cloudgaming,driver>=550,driver<551\n",
      "NVIDIA_VISIBLE_DEVICES=all\n",
      "NV_CUDA_CUDART_DEV_VERSION=12.5.82-1\n",
      "NV_CUDA_CUDART_VERSION=12.5.82-1\n",
      "NV_CUDA_LIB_VERSION=12.5.1-1\n",
      "NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE=cuda-nsight-compute-12-5=12.5.1-1\n",
      "NV_CUDA_NSIGHT_COMPUTE_VERSION=12.5.1-1\n",
      "NV_CUDNN_PACKAGE=libcudnn9-cuda-12=9.2.1.18-1\n",
      "NV_CUDNN_PACKAGE_DEV=libcudnn9-dev-cuda-12=9.2.1.18-1\n",
      "NV_CUDNN_PACKAGE_NAME=libcudnn9-cuda-12\n",
      "NV_CUDNN_VERSION=9.2.1.18-1\n",
      "NV_LIBCUBLAS_DEV_PACKAGE=libcublas-dev-12-5=12.5.3.2-1\n",
      "NV_LIBCUBLAS_DEV_PACKAGE_NAME=libcublas-dev-12-5\n",
      "NV_LIBCUBLAS_DEV_VERSION=12.5.3.2-1\n",
      "NV_LIBCUBLAS_PACKAGE=libcublas-12-5=12.5.3.2-1\n",
      "NV_LIBCUBLAS_PACKAGE_NAME=libcublas-12-5\n",
      "NV_LIBCUBLAS_VERSION=12.5.3.2-1\n",
      "NV_LIBCUSPARSE_DEV_VERSION=12.5.1.3-1\n",
      "NV_LIBCUSPARSE_VERSION=12.5.1.3-1\n",
      "NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
      "NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
      "NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
      "NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
      "NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
      "NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
      "NV_LIBNPP_DEV_PACKAGE=libnpp-dev-12-5=12.3.0.159-1\n",
      "NV_LIBNPP_DEV_VERSION=12.3.0.159-1\n",
      "NV_LIBNPP_PACKAGE=libnpp-12-5=12.3.0.159-1\n",
      "NV_LIBNPP_VERSION=12.3.0.159-1\n",
      "NV_NVML_DEV_VERSION=12.5.82-1\n",
      "NV_NVPROF_DEV_PACKAGE=cuda-nvprof-12-5=12.5.82-1\n",
      "NV_NVPROF_VERSION=12.5.82-1\n",
      "NV_NVTX_VERSION=12.5.82-1\n",
      "OLDPWD=/\n",
      "PAGER=cat\n",
      "PATH=/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
      "PWD=/content/sam2\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "PYTHONPATH=/env/python\n",
      "PYTHONUTF8=1\n",
      "PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n",
      "QT_QPA_FONTDIR=/usr/local/lib/python3.11/dist-packages/cv2/qt/fonts\n",
      "QT_QPA_PLATFORM_PLUGIN_PATH=/usr/local/lib/python3.11/dist-packages/cv2/qt/plugins\n",
      "RANK=0\n",
      "SHELL=/bin/bash\n",
      "SHLVL=0\n",
      "TBE_CREDS_ADDR=172.28.0.1:8008\n",
      "TBE_EPHEM_CREDS_ADDR=172.28.0.1:8009\n",
      "TBE_RUNTIME_ADDR=172.28.0.1:8011\n",
      "TCLLIBPATH=/usr/share/tcltk/tcllib1.20\n",
      "TERM=xterm-color\n",
      "TF2_BEHAVIOR=1\n",
      "TF_CPP_MIN_LOG_LEVEL=1\n",
      "TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "TORCH_NCCL_ASYNC_ERROR_HANDLING=1\n",
      "TPU_ML_PLATFORM=Tensorflow\n",
      "TPU_ML_PLATFORM_VERSION=2.18.0\n",
      "UV_BUILD_CONSTRAINT=\n",
      "UV_CONSTRAINT=\n",
      "UV_INSTALL_DIR=/usr/local/bin\n",
      "UV_SYSTEM_PYTHON=true\n",
      "VM_GCE_METADATA_HOST=169.254.169.253\n",
      "WORLD_SIZE=1\n",
      "_=/usr/local/bin/python\n",
      "_PYVIZ_COMMS_INSTALLED=1\n",
      "\n",
      "INFO 2025-05-14 14:09:24,380 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.\n",
      "INFO 2025-05-14 14:09:24,381 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: /content/logs/tensorboard\n",
      "INFO 2025-05-14 14:09:25,238 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5\n",
      "INFO 2025-05-14 14:09:25,241 trainer.py:1059: ====================\n",
      "INFO 2025-05-14 14:09:25,241 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>\n",
      "INFO 2025-05-14 14:09:25,244 trainer.py:1061: Model is SAM2Train(\n",
      "  (image_encoder): ImageEncoder(\n",
      "    (trunk): Hiera(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      )\n",
      "      (blocks): ModuleList(\n",
      "        (0): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=112, out_features=336, bias=True)\n",
      "            (proj): Linear(in_features=112, out_features=112, bias=True)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=112, out_features=448, bias=True)\n",
      "              (1): Linear(in_features=448, out_features=112, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (1): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=112, out_features=336, bias=True)\n",
      "            (proj): Linear(in_features=112, out_features=112, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=112, out_features=448, bias=True)\n",
      "              (1): Linear(in_features=448, out_features=112, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (2): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "            (qkv): Linear(in_features=112, out_features=672, bias=True)\n",
      "            (proj): Linear(in_features=224, out_features=224, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=224, out_features=896, bias=True)\n",
      "              (1): Linear(in_features=896, out_features=224, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "          (proj): Linear(in_features=112, out_features=224, bias=True)\n",
      "        )\n",
      "        (3-4): 2 x MultiScaleBlock(\n",
      "          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=224, out_features=672, bias=True)\n",
      "            (proj): Linear(in_features=224, out_features=224, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=224, out_features=896, bias=True)\n",
      "              (1): Linear(in_features=896, out_features=224, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (5): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "            (qkv): Linear(in_features=224, out_features=1344, bias=True)\n",
      "            (proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=448, out_features=1792, bias=True)\n",
      "              (1): Linear(in_features=1792, out_features=448, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "          (proj): Linear(in_features=224, out_features=448, bias=True)\n",
      "        )\n",
      "        (6-20): 15 x MultiScaleBlock(\n",
      "          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=448, out_features=1344, bias=True)\n",
      "            (proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=448, out_features=1792, bias=True)\n",
      "              (1): Linear(in_features=1792, out_features=448, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (21): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "            (qkv): Linear(in_features=448, out_features=2688, bias=True)\n",
      "            (proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
      "              (1): Linear(in_features=3584, out_features=896, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "          (proj): Linear(in_features=448, out_features=896, bias=True)\n",
      "        )\n",
      "        (22-23): 2 x MultiScaleBlock(\n",
      "          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=896, out_features=2688, bias=True)\n",
      "            (proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
      "              (1): Linear(in_features=3584, out_features=896, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (neck): FpnNeck(\n",
      "      (position_encoding): PositionEmbeddingSine()\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (memory_attention): MemoryAttention(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x MemoryAttentionLayer(\n",
      "        (self_attn): RoPEAttention(\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (cross_attn_image): RoPEAttention(\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (k_proj): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (memory_encoder): MemoryEncoder(\n",
      "    (mask_downsampler): MaskDownSampler(\n",
      "      (encoder): Sequential(\n",
      "        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): LayerNorm2d()\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (4): LayerNorm2d()\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (7): LayerNorm2d()\n",
      "        (8): GELU(approximate='none')\n",
      "        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (10): LayerNorm2d()\n",
      "        (11): GELU(approximate='none')\n",
      "        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fuser): Fuser(\n",
      "      (proj): Identity()\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x CXBlock(\n",
      "          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "          (norm): LayerNorm2d()\n",
      "          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (position_encoding): PositionEmbeddingSine()\n",
      "    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (sam_prompt_encoder): PromptEncoder(\n",
      "    (pe_layer): PositionEmbeddingRandom()\n",
      "    (point_embeddings): ModuleList(\n",
      "      (0-3): 4 x Embedding(1, 256)\n",
      "    )\n",
      "    (not_a_point_embed): Embedding(1, 256)\n",
      "    (mask_downscaling): Sequential(\n",
      "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): LayerNorm2d()\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (4): LayerNorm2d()\n",
      "      (5): GELU(approximate='none')\n",
      "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (no_mask_embed): Embedding(1, 256)\n",
      "  )\n",
      "  (sam_mask_decoder): MaskDecoder(\n",
      "    (transformer): TwoWayTransformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TwoWayAttentionBlock(\n",
      "          (self_attn): Attention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_token_to_image): Attention(\n",
      "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "            )\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_image_to_token): Attention(\n",
      "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_attn_token_to_image): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (iou_token): Embedding(1, 256)\n",
      "    (mask_tokens): Embedding(4, 256)\n",
      "    (obj_score_token): Embedding(1, 256)\n",
      "    (output_upscaling): Sequential(\n",
      "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): LayerNorm2d()\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (4): GELU(approximate='none')\n",
      "    )\n",
      "    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (output_hypernetworks_mlps): ModuleList(\n",
      "      (0-3): 4 x MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
      "        )\n",
      "        (act): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (iou_prediction_head): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "      )\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (pred_obj_score_head): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "      )\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (obj_ptr_proj): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)\n",
      ")\n",
      "INFO 2025-05-14 14:09:25,318 trainer.py:1062: \tTotal parameters 80.9 M\n",
      "INFO 2025-05-14 14:09:25,319 trainer.py:1063: \tTrainable parameters 80.9 M\n",
      "INFO 2025-05-14 14:09:25,319 trainer.py:1066: \tNon-Trainable parameters 0  \n",
      "INFO 2025-05-14 14:09:25,319 trainer.py:1069: ====================\n",
      "INFO 2025-05-14 14:09:25,322 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.\n",
      "INFO 2025-05-14 14:09:25,322 trainer.py: 314: Moving components to device cuda:0 and local rank 0.\n",
      "INFO 2025-05-14 14:09:25,433 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.\n",
      "INFO 2025-05-14 14:09:25,446 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.norm1.bias'}\n",
      "INFO 2025-05-14 14:09:25,521 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.19.norm1.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'memory_attention.layers.3.norm2.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'memory_attention.layers.2.norm2.bias', 'memory_encoder.out_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'obj_ptr_proj.layers.0.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'memory_encoder.pix_feat_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'memory_attention.layers.2.norm3.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'memory_attention.layers.3.linear1.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'memory_attention.layers.1.norm2.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'memory_attention.layers.0.linear1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'memory_attention.layers.1.norm3.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'memory_attention.layers.2.linear2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'memory_attention.layers.1.linear2.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'memory_attention.layers.3.norm3.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'sam_mask_decoder.conv_s0.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.norm1.bias'}\n",
      "INFO 2025-05-14 14:09:25,620 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'memory_attention.layers.2.norm3.weight', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'memory_attention.layers.2.norm1.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'memory_attention.layers.3.norm3.weight', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'memory_attention.layers.1.norm3.bias', 'memory_attention.layers.3.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'memory_attention.layers.3.norm3.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'memory_attention.layers.2.norm2.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.22.norm1.bias'} \n",
      "Raw dataset length = 22\n",
      "INFO 2025-05-14 14:09:25,975 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]\n",
      "INFO 2025-05-14 14:09:26,184 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': './checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}\n",
      "/content/sam2/training/trainer.py:861: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [64, 256, 1, 1], strides() = [256, 1, 256, 256]\n",
      "bucket_view.sizes() = [64, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "INFO 2025-05-14 14:09:40,662 train_utils.py: 271: Train Epoch: [0][ 0/44] | Batch Time: 14.02 (14.02) | Data Time: 9.33 (9.33) | Mem (GB): 17.00 (17.00/17.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.08e+00 (1.08e+00)\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/content/sam2/training/train.py\", line 270, in <module>\n",
      "[rank0]:     main(args)\n",
      "[rank0]:   File \"/content/sam2/training/train.py\", line 240, in main\n",
      "[rank0]:     single_node_runner(cfg, main_port)\n",
      "[rank0]:   File \"/content/sam2/training/train.py\", line 53, in single_node_runner\n",
      "[rank0]:     single_proc_run(local_rank=0, main_port=main_port, cfg=cfg, world_size=num_proc)\n",
      "[rank0]:   File \"/content/sam2/training/train.py\", line 41, in single_proc_run\n",
      "[rank0]:     trainer.run()\n",
      "[rank0]:   File \"/content/sam2/training/trainer.py\", line 515, in run\n",
      "[rank0]:     self.run_train()\n",
      "[rank0]:   File \"/content/sam2/training/trainer.py\", line 532, in run_train\n",
      "[rank0]:     outs = self.train_epoch(dataloader)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/content/sam2/training/trainer.py\", line 749, in train_epoch\n",
      "[rank0]:     self._run_step(batch, phase, loss_mts, extra_loss_mts)\n",
      "[rank0]:   File \"/content/sam2/training/trainer.py\", line 865, in _run_step\n",
      "[rank0]:     loss_dict, batch_size, extra_losses = self._step(\n",
      "[rank0]:                                           ^^^^^^^^^^^\n",
      "[rank0]:   File \"/content/sam2/training/trainer.py\", line 462, in _step\n",
      "[rank0]:     loss = self.loss[key](outputs, targets)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/content/sam2/training/loss_fns.py\", line 178, in forward\n",
      "[rank0]:     cur_losses = self._forward(outs, targets, num_objects)\n",
      "[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/content/sam2/training/loss_fns.py\", line 212, in _forward\n",
      "[rank0]:     self._update_losses(\n",
      "[rank0]:   File \"/content/sam2/training/loss_fns.py\", line 223, in _update_losses\n",
      "[rank0]:     loss_multimask = sigmoid_focal_loss(\n",
      "[rank0]:                      ^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/content/sam2/training/loss_fns.py\", line 83, in sigmoid_focal_loss\n",
      "[rank0]:     alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
      "[rank0]:                                                ~~^~~~~~~~~\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 39, in wrapped\n",
      "[rank0]:     return f(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 1073, in __rsub__\n",
      "[rank0]:     return _C._VariableFunctions.rsub(self, other)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 27.38 MiB is free. Process 126544 has 22.13 GiB memory in use. Of the allocated memory 21.39 GiB is allocated by PyTorch, and 174.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[rank0]:[W514 14:09:49.030313354 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/sam2\n",
    "\n",
    "# Lancement direct en pointant sur le YAML complet\n",
    "!python training/train.py \\\n",
    "-c /workspace/sam2/sam2/configs/sam2.1_training/sam2.1_hiera_b+_MOSE_finetune.yaml \\\n",
    "--use-cluster 0 \\\n",
    "--num-gpus 1\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
