{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ‚öôÔ∏è CONFIGURATION CENTRALIS√âE\n",
        "# =============================================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# =============================================================================\n",
        "# üåç D√âTECTION AUTOMATIQUE DE L'ENVIRONNEMENT\n",
        "# =============================================================================\n",
        "\n",
        "def detect_environment():\n",
        "    \"\"\"D√©tecte automatiquement si on est sur Colab ou en local\"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# =============================================================================\n",
        "# üìã CONFIGURATION PRINCIPALE\n",
        "# =============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration centralis√©e du projet\"\"\"\n",
        "    \n",
        "    # üåç Environnement\n",
        "    USING_COLAB = detect_environment()\n",
        "    \n",
        "    # üé¨ VID√âO ET PROJET  \n",
        "    VIDEO_NAME = \"SD_13_06_2025_1_PdB_S1_T959s\"  # ‚ö†Ô∏è MODIFIEZ ICI\n",
        "    FRAME_INTERVAL = 3                            # ‚ö†Ô∏è MODIFIEZ ICI\n",
        "    \n",
        "    # üé¨ OPTIONS D'EXTRACTION\n",
        "    EXTRACT_FRAMES = True                         # ‚ö†Ô∏è MODIFIEZ ICI\n",
        "    FORCE_EXTRACTION = False                      # ‚ö†Ô∏è MODIFIEZ ICI\n",
        "    \n",
        "    # ü§ñ SAM2 CONFIGURATION\n",
        "    SAM2_MODEL = \"sam2.1_hiera_l\"                # ou \"sam2.1_hiera_s\" pour small\n",
        "    SAM2_CHECKPOINT = \"sam2.1_hiera_large.pt\"    # ou \"sam2.1_hiera_small.pt\"\n",
        "    \n",
        "    # üóÇÔ∏è CHEMINS AUTOMATIQUES\n",
        "    @property\n",
        "    def videos_dir(self):\n",
        "        return Path(\"./videos\") if self.USING_COLAB else Path(\"../data/videos\")\n",
        "    \n",
        "    @property \n",
        "    def checkpoint_path(self):\n",
        "        base = \"../../checkpoints\" if self.USING_COLAB else \"../checkpoints\"\n",
        "        return Path(base) / self.SAM2_CHECKPOINT\n",
        "    \n",
        "    @property\n",
        "    def model_config_path(self):\n",
        "        return f\"configs/sam2.1/{self.SAM2_MODEL}.yaml\"\n",
        "    \n",
        "    # üé¨ CHEMINS VID√âO\n",
        "    @property\n",
        "    def video_path(self):\n",
        "        return self.videos_dir / f\"{self.VIDEO_NAME}.mp4\"\n",
        "    \n",
        "    @property\n",
        "    def config_path(self):\n",
        "        return self.videos_dir / f\"{self.VIDEO_NAME}_config.json\"\n",
        "    \n",
        "    @property\n",
        "    def output_dir(self):\n",
        "        return self.videos_dir / \"outputs\" / self.VIDEO_NAME\n",
        "    \n",
        "    @property\n",
        "    def frames_dir(self):\n",
        "        return self.output_dir / \"frames\"\n",
        "    \n",
        "    @property\n",
        "    def masks_dir(self):\n",
        "        return self.output_dir / \"masks\"\n",
        "    \n",
        "    @property\n",
        "    def output_video_path(self):\n",
        "        return self.output_dir / f\"{self.VIDEO_NAME}_annotated.mp4\"\n",
        "    \n",
        "    @property\n",
        "    def output_json_path(self):\n",
        "        return self.output_dir / f\"{self.VIDEO_NAME}_project.json\"\n",
        "    \n",
        "    def setup_directories(self):\n",
        "        \"\"\"Cr√©e tous les dossiers n√©cessaires (sans v√©rifier les fichiers)\"\"\"\n",
        "        print(\"üèóÔ∏è Cr√©ation de la structure de dossiers...\")\n",
        "        self.videos_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.frames_dir.mkdir(exist_ok=True)\n",
        "        self.masks_dir.mkdir(exist_ok=True)\n",
        "        print(f\"   ‚úÖ Dossiers cr√©√©s dans: {self.output_dir}\")\n",
        "    \n",
        "    def check_files_exist(self):\n",
        "        \"\"\"V√©rifie si les fichiers requis existent (sans lever d'erreur)\"\"\"\n",
        "        video_exists = self.video_path.exists()\n",
        "        config_exists = self.config_path.exists()\n",
        "        \n",
        "        print(f\"üìÑ V√©rification des fichiers:\")\n",
        "        print(f\"   üé¨ Vid√©o: {'‚úÖ' if video_exists else '‚ùå'} {self.video_path}\")\n",
        "        print(f\"   üìÑ Config: {'‚úÖ' if config_exists else '‚ùå'} {self.config_path}\")\n",
        "        \n",
        "        return video_exists and config_exists\n",
        "    \n",
        "    def wait_for_files(self, max_wait_minutes=10, check_interval=10):\n",
        "        \"\"\"Attend que les fichiers soient disponibles (utile pour Colab)\"\"\"\n",
        "        if not self.USING_COLAB:\n",
        "            # En local, validation imm√©diate\n",
        "            if not self.check_files_exist():\n",
        "                missing = []\n",
        "                if not self.video_path.exists():\n",
        "                    missing.append(f\"vid√©o: {self.video_path}\")\n",
        "                if not self.config_path.exists():\n",
        "                    missing.append(f\"config: {self.config_path}\")\n",
        "                raise FileNotFoundError(f\"‚ùå Fichiers manquants: {', '.join(missing)}\")\n",
        "            return True\n",
        "        \n",
        "        # Sur Colab, attente avec timeout\n",
        "        print(f\"‚è≥ Attente des fichiers (max {max_wait_minutes}min)...\")\n",
        "        start_time = time.time()\n",
        "        max_wait_seconds = max_wait_minutes * 60\n",
        "        \n",
        "        while time.time() - start_time < max_wait_seconds:\n",
        "            if self.check_files_exist():\n",
        "                print(\"‚úÖ Tous les fichiers sont disponibles!\")\n",
        "                return True\n",
        "            \n",
        "            elapsed = int(time.time() - start_time)\n",
        "            remaining = max_wait_seconds - elapsed\n",
        "            print(f\"   ‚è≥ Attente... ({elapsed}s √©coul√©es, {remaining}s restantes)\")\n",
        "            time.sleep(check_interval)\n",
        "        \n",
        "        print(f\"‚ö†Ô∏è Timeout atteint ({max_wait_minutes}min)\")\n",
        "        return False\n",
        "    \n",
        "    def validate_files_now(self):\n",
        "        \"\"\"Validation imm√©diate avec erreur si fichiers manquants\"\"\"\n",
        "        if not self.video_path.exists():\n",
        "            raise FileNotFoundError(f\"‚ùå Vid√©o non trouv√©e: {self.video_path}\")\n",
        "        if not self.config_path.exists():\n",
        "            raise FileNotFoundError(f\"‚ùå Fichier config non trouv√©: {self.config_path}\")\n",
        "        print(\"‚úÖ Tous les fichiers sont valides\")\n",
        "    \n",
        "    def display_config(self):\n",
        "        \"\"\"Affiche la configuration actuelle\"\"\"\n",
        "        print(f\"üìã CONFIGURATION CENTRALIS√âE:\")\n",
        "        print(f\"   üåç Environnement: {'üî¨ Colab' if self.USING_COLAB else 'üñ•Ô∏è Local'}\")\n",
        "        print(f\"   üé¨ Vid√©o: {self.VIDEO_NAME}\")\n",
        "        print(f\"   ‚èØÔ∏è  Intervalle frames: {self.FRAME_INTERVAL}\")\n",
        "        print(f\"   üé¨ Extraction: {'‚úÖ Activ√©e' if self.EXTRACT_FRAMES else '‚ùå D√©sactiv√©e'}\")\n",
        "        print(f\"   üîÑ Force extraction: {'‚úÖ Oui' if self.FORCE_EXTRACTION else '‚ùå Non'}\")\n",
        "        print(f\"   ü§ñ Mod√®le SAM2: {self.SAM2_MODEL}\")\n",
        "        print(f\"   üìÅ Dossier vid√©os: {self.videos_dir}\")\n",
        "        print(f\"   üìÑ Fichier config: {self.config_path}\")\n",
        "        print(f\"   üìÅ Sortie: {self.output_dir}\")\n",
        "        print(f\"   üíæ Checkpoint: {self.checkpoint_path}\")\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ INITIALISATION\n",
        "# =============================================================================\n",
        "\n",
        "# Cr√©ation de l'instance de configuration\n",
        "cfg = Config()\n",
        "\n",
        "# Setup automatique des dossiers (toujours safe)\n",
        "cfg.setup_directories()\n",
        "cfg.display_config()\n",
        "\n",
        "# V√©rification des fichiers selon l'environnement\n",
        "if cfg.USING_COLAB:\n",
        "    print(f\"\\nüî¨ Mode Colab d√©tect√©:\")\n",
        "    print(f\"   üí° Les dossiers sont cr√©√©s, vous pouvez maintenant uploader vos fichiers\")\n",
        "    print(f\"   üì§ Uploadez dans: {cfg.videos_dir}\")\n",
        "    print(f\"   üìÑ Fichiers attendus:\")\n",
        "    print(f\"      ‚Ä¢ {cfg.video_path.name}\")\n",
        "    print(f\"      ‚Ä¢ {cfg.config_path.name}\")\n",
        "    \n",
        "    # V√©rification simple sans erreur\n",
        "    cfg.check_files_exist()\n",
        "    print(f\"   üí° Utilisez cfg.wait_for_files() quand les uploads sont termin√©s\")\n",
        "else:\n",
        "    print(f\"\\nüñ•Ô∏è Mode Local d√©tect√©:\")\n",
        "    # Validation imm√©diate en local\n",
        "    cfg.validate_files_now()\n",
        "\n",
        "print(\"\\n‚úÖ Configuration centralis√©e initialis√©e!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üîß INSTALLATION ET SETUP SAM2 (AUTO-INSTALL COLAB)\n",
        "# =============================================================================\n",
        "\n",
        "def is_sam2_installed():\n",
        "    \"\"\"V√©rifie si SAM 2 est d√©j√† install√©\"\"\"\n",
        "    try:\n",
        "        import sam2\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "def install_sam2_colab(cfg):\n",
        "    \"\"\"Installation compl√®te de SAM2 sur Colab avec chemins de la config\"\"\"\n",
        "    print(\"üîß Installation de SAM 2 en cours...\")\n",
        "    \n",
        "    # Packages de base\n",
        "    print(\"   üì¶ Installation des d√©pendances...\")\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam2.git'\n",
        "    \n",
        "    # Cr√©ation du dossier checkpoints (utilise la config)\n",
        "    checkpoint_dir = cfg.checkpoint_path.parent\n",
        "    print(f\"   üìÅ Cr√©ation du dossier checkpoints: {checkpoint_dir}\")\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # T√©l√©chargement du mod√®le configur√©\n",
        "    checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything_2/092824\"\n",
        "    model_file = cfg.SAM2_CHECKPOINT\n",
        "    \n",
        "    print(f\"   ‚¨áÔ∏è T√©l√©chargement du mod√®le: {model_file}\")\n",
        "    !wget -P {checkpoint_dir} -q {checkpoint_url}/{model_file}\n",
        "    \n",
        "    # Optionnel: t√©l√©charger l'autre mod√®le si besoin\n",
        "    if \"large\" in model_file:\n",
        "        other_model = \"sam2.1_hiera_small.pt\"\n",
        "        print(f\"   üì¶ Mod√®le small √©galement disponible: {other_model}\")\n",
        "        # !wget -P {checkpoint_dir} -q {checkpoint_url}/{other_model}\n",
        "    else:\n",
        "        other_model = \"sam2.1_hiera_large.pt\"\n",
        "        print(f\"   üì¶ Mod√®le large √©galement disponible: {other_model}\")\n",
        "        # !wget -P {checkpoint_dir} -q {checkpoint_url}/{other_model}\n",
        "    \n",
        "    # Nettoyage Colab\n",
        "    if cfg.USING_COLAB:\n",
        "        print(\"   üßπ Nettoyage des fichiers temporaires Colab...\")\n",
        "        !rm -rf /content/sample_data/* 2>/dev/null || true\n",
        "    \n",
        "    # Nettoyage m√©moire\n",
        "    import gc\n",
        "    import torch\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"   üî• M√©moire GPU nettoy√©e\")\n",
        "    \n",
        "    print(\"‚úÖ Installation de SAM 2 termin√©e\")\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ AUTO-SETUP SAM2 INTELLIGENT\n",
        "# =============================================================================\n",
        "\n",
        "print(\"ü§ñ V√©rification et setup SAM2...\")\n",
        "\n",
        "# V√©rifications\n",
        "sam2_installed = is_sam2_installed()\n",
        "checkpoint_available = cfg.checkpoint_path.exists()\n",
        "\n",
        "print(f\"   üì¶ SAM2 install√©: {'‚úÖ' if sam2_installed else '‚ùå'}\")\n",
        "print(f\"   üíæ Checkpoint disponible: {'‚úÖ' if checkpoint_available else '‚ùå'} {cfg.checkpoint_path}\")\n",
        "\n",
        "# Logique d'installation\n",
        "if cfg.USING_COLAB and (not sam2_installed or not checkpoint_available):\n",
        "    print(f\"üî¨ Colab d√©tect√© - Installation automatique...\")\n",
        "    install_sam2_colab(cfg)\n",
        "    \n",
        "elif cfg.USING_COLAB and sam2_installed and checkpoint_available:\n",
        "    print(\"‚úÖ SAM 2 d√©j√† install√© sur Colab - SKIP installation\")\n",
        "    \n",
        "elif not cfg.USING_COLAB:\n",
        "    print(\"üñ•Ô∏è Mode local d√©tect√©\")\n",
        "    if not sam2_installed:\n",
        "        print(\"   ‚ö†Ô∏è SAM2 non install√©. Installez avec: pip install git+https://github.com/facebookresearch/sam2.git\")\n",
        "    if not checkpoint_available:\n",
        "        print(f\"   ‚ö†Ô∏è Checkpoint manquant: {cfg.checkpoint_path}\")\n",
        "        print(\"   üí° T√©l√©chargez depuis: https://github.com/facebookresearch/sam2#download-checkpoints\")\n",
        "    \n",
        "    if sam2_installed and checkpoint_available:\n",
        "        print(\"‚úÖ SAM2 pr√™t en mode local\")\n",
        "\n",
        "print(\"‚úÖ Setup SAM2 termin√©\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k83nNbwoAdf1",
        "outputId": "4f54ec69-dede-40eb-ff63-cac024309b91"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üì¶ IMPORTS ET CONFIGURATION ENVIRONNEMENT\n",
        "# =============================================================================\n",
        "\n",
        "# ==================== IMPORTS SYST√àME ====================\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "import uuid\n",
        "import base64\n",
        "\n",
        "# ==================== IMPORTS SCIENTIFIQUES ====================\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==================== IMPORTS DEEP LEARNING ====================\n",
        "import torch\n",
        "import torchvision\n",
        "from pycocotools.mask import encode as encode_rle\n",
        "\n",
        "# =============================================================================\n",
        "# üñ•Ô∏è CONFIGURATION AUTOMATIQUE DU DEVICE ET OPTIMISATIONS\n",
        "# =============================================================================\n",
        "\n",
        "def setup_torch_environment(verbose=True):\n",
        "    \"\"\"Configure automatiquement l'environnement PyTorch optimal\"\"\"\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"üîß Configuration de l'environnement PyTorch...\")\n",
        "        print(f\"   üì¶ PyTorch version: {torch.__version__}\")\n",
        "        print(f\"   üì¶ Torchvision version: {torchvision.__version__}\")\n",
        "    \n",
        "    # === S√âLECTION DU DEVICE ===\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "        if verbose:\n",
        "            print(f\"   üî• CUDA disponible: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        if verbose:\n",
        "            print(f\"   üçé MPS (Apple Silicon) disponible\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        if verbose:\n",
        "            print(f\"   üíª CPU seulement\")\n",
        "    \n",
        "    # === OPTIMISATIONS CUDA ===\n",
        "    optimizations_applied = []\n",
        "    \n",
        "    if device.type == \"cuda\":\n",
        "        # Autocast pour √©conomiser la m√©moire\n",
        "        torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
        "        optimizations_applied.append(\"Autocast bfloat16\")\n",
        "        \n",
        "        # Optimisations TensorFloat-32 (si GPU r√©cent)\n",
        "        gpu_compute_capability = torch.cuda.get_device_properties(0).major\n",
        "        if gpu_compute_capability >= 8:  # Ampere et plus r√©cent\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "            optimizations_applied.append(\"TensorFloat-32\")\n",
        "        \n",
        "        # Optimisations m√©moire additionnelles\n",
        "        torch.backends.cudnn.benchmark = True  # Optimise pour tailles fixes\n",
        "        optimizations_applied.append(\"cuDNN benchmark\")\n",
        "    \n",
        "    if verbose and optimizations_applied:\n",
        "        print(f\"   ‚ö° Optimisations activ√©es: {', '.join(optimizations_applied)}\")\n",
        "    \n",
        "    return device, optimizations_applied\n",
        "\n",
        "def display_system_info(device):\n",
        "    \"\"\"Affiche les informations syst√®me d√©taill√©es\"\"\"\n",
        "    print(f\"\\nüìä INFORMATIONS SYST√àME:\")\n",
        "    print(f\"   üñ•Ô∏è  Device principal: {device}\")\n",
        "    \n",
        "    if device.type == \"cuda\":\n",
        "        print(f\"   üî• GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   üíæ M√©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
        "        print(f\"   üßÆ Compute Capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}\")\n",
        "    \n",
        "    # CPU Info\n",
        "    import platform\n",
        "    print(f\"   üíª CPU: {platform.processor()}\")\n",
        "    print(f\"   üß† Threads: {torch.get_num_threads()}\")\n",
        "    \n",
        "    # Versions importantes\n",
        "    print(f\"   üêç Python: {platform.python_version()}\")\n",
        "    print(f\"   üì¶ NumPy: {np.__version__}\")\n",
        "    print(f\"   üé• OpenCV: {cv2.__version__}\")\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ INITIALISATION ENVIRONNEMENT\n",
        "# =============================================================================\n",
        "\n",
        "# Configuration automatique\n",
        "device, optimizations = setup_torch_environment(verbose=True)\n",
        "\n",
        "# Ajout du device √† notre configuration centralis√©e\n",
        "if 'cfg' in globals():\n",
        "    cfg.device = device\n",
        "    cfg.torch_optimizations = optimizations\n",
        "    print(f\"‚úÖ Device ajout√© √† la configuration: cfg.device = {device}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Configuration cfg non trouv√©e - device disponible en tant que variable globale\")\n",
        "\n",
        "# Affichage des informations syst√®me (optionnel, d√©commentez si besoin)\n",
        "# display_system_info(device)\n",
        "\n",
        "# Nettoyage initial de la m√©moire\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"\\n‚úÖ Environnement PyTorch configur√© et optimis√©!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üìÑ CHARGEMENT ET VALIDATION DE LA CONFIGURATION JSON\n",
        "# =============================================================================\n",
        "\n",
        "def load_and_validate_project_config(config_path: Path) -> Dict[str, Any]:\n",
        "    \"\"\"Charge et valide le fichier de configuration JSON du projet.\"\"\"\n",
        "    print(f\"üìÑ Chargement de la configuration projet: {config_path}\")\n",
        "\n",
        "    # V√©rification existence du fichier\n",
        "    if not config_path.exists():\n",
        "        raise FileNotFoundError(f\"‚ùå Fichier config non trouv√©: {config_path}\")\n",
        "\n",
        "    try:\n",
        "        with open(config_path, 'r', encoding='utf-8') as f:\n",
        "            config = json.load(f)\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"‚ùå Erreur JSON dans {config_path}: {e}\")\n",
        "\n",
        "    # === VALIDATION DE LA STRUCTURE ===\n",
        "    required_sections = ['calibration', 'objects', 'initial_annotations']\n",
        "    missing_sections = [section for section in required_sections if section not in config]\n",
        "    \n",
        "    if missing_sections:\n",
        "        raise ValueError(f\"‚ùå Sections manquantes dans le config: {missing_sections}\")\n",
        "\n",
        "    # === VALIDATION DES DONN√âES ===\n",
        "    \n",
        "    # Validation calibration\n",
        "    if 'camera_parameters' not in config['calibration']:\n",
        "        raise ValueError(\"‚ùå 'camera_parameters' manquant dans la calibration\")\n",
        "    \n",
        "    # Validation objets\n",
        "    if not config['objects']:\n",
        "        raise ValueError(\"‚ùå Aucun objet d√©fini dans la configuration\")\n",
        "    \n",
        "    # Validation annotations initiales\n",
        "    if not config['initial_annotations']:\n",
        "        raise ValueError(\"‚ùå Aucune annotation initiale d√©finie\")\n",
        "\n",
        "    # === STATISTIQUES ET R√âSUM√â ===\n",
        "    num_objects = len(config['objects'])\n",
        "    \n",
        "    # Comptage des annotations\n",
        "    total_annotations = 0\n",
        "    annotation_frames = set()\n",
        "    for frame_data in config['initial_annotations']:\n",
        "        frame_idx = frame_data.get('frame')\n",
        "        annotations = frame_data.get('annotations', [])\n",
        "        total_annotations += len(annotations)\n",
        "        annotation_frames.add(frame_idx)\n",
        "\n",
        "    # Types d'objets\n",
        "    obj_types = {}\n",
        "    obj_by_type = {}\n",
        "    for obj in config['objects']:\n",
        "        obj_type = obj.get('obj_type', 'unknown')\n",
        "        obj_types[obj_type] = obj_types.get(obj_type, 0) + 1\n",
        "        if obj_type not in obj_by_type:\n",
        "            obj_by_type[obj_type] = []\n",
        "        obj_by_type[obj_type].append(obj.get('obj_id', 'no_id'))\n",
        "\n",
        "    print(f\"‚úÖ Configuration projet charg√©e et valid√©e:\")\n",
        "    print(f\"   üì∑ Calibration cam√©ra: ‚úÖ OK\")\n",
        "    print(f\"   üéØ Objets d√©finis: {num_objects}\")\n",
        "    print(f\"   üìç Annotations initiales: {total_annotations} sur {len(annotation_frames)} frames\")\n",
        "    print(f\"   üè∑Ô∏è  Types d'objets:\")\n",
        "    for obj_type, count in obj_types.items():\n",
        "        ids = obj_by_type[obj_type]\n",
        "        print(f\"      ‚Ä¢ {obj_type}: {count} ({ids})\")\n",
        "\n",
        "    return config\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ CHARGEMENT INTELLIGENT DE LA CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "# Chargement avec gestion intelligente Colab/Local\n",
        "if cfg.USING_COLAB:\n",
        "    print(\"üî¨ Mode Colab d√©tect√© pour le chargement config\")\n",
        "    if cfg.config_path.exists():\n",
        "        project_config = load_and_validate_project_config(cfg.config_path)\n",
        "    else:\n",
        "        print(f\"‚è≥ Fichier config pas encore upload√©, utilisez:\")\n",
        "        print(f\"   project_config = wait_and_load_config(cfg)\")\n",
        "        project_config = None\n",
        "else:\n",
        "    print(\"üñ•Ô∏è Mode local: chargement imm√©diat\")\n",
        "    project_config = load_and_validate_project_config(cfg.config_path)\n",
        "\n",
        "if project_config:\n",
        "    print(\"\\n‚úÖ Configuration projet pr√™te √† l'usage!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üé¨ EXTRACTION DES FRAMES\n",
        "# =============================================================================\n",
        "\n",
        "def extract_frames(video_path: Path, frames_dir: Path, frame_interval: int = 1, force_extraction: bool = False) -> int:\n",
        "    \"\"\"Extrait les frames de la vid√©o selon l'intervalle sp√©cifi√©.\"\"\"\n",
        "\n",
        "    print(f\"üé¨ Extraction des frames...\")\n",
        "    print(f\"   üìπ Source: {video_path}\")\n",
        "    print(f\"   üìÅ Destination: {frames_dir}\")\n",
        "    print(f\"   ‚èØÔ∏è  Intervalle: {frame_interval}\")\n",
        "    print(f\"   üîÑ Force extraction: {'‚úÖ Oui' if force_extraction else '‚ùå Non'}\")\n",
        "\n",
        "    # V√©rification existence du fichier vid√©o\n",
        "    if not video_path.exists():\n",
        "        raise FileNotFoundError(f\"‚ùå Vid√©o non trouv√©e: {video_path}\")\n",
        "\n",
        "    # V√©rification si extraction d√©j√† faite\n",
        "    existing_frames = list(frames_dir.glob(\"*.jpg\"))\n",
        "    if existing_frames and not force_extraction:\n",
        "        print(f\"üìÇ {len(existing_frames)} frames d√©j√† extraites - SKIP\")\n",
        "        return len(existing_frames)\n",
        "    elif existing_frames and force_extraction:\n",
        "        print(f\"üîÑ {len(existing_frames)} frames existantes - SUPPRESSION et r√©-extraction...\")\n",
        "        # Supprimer les frames existantes\n",
        "        for frame_file in existing_frames:\n",
        "            frame_file.unlink()\n",
        "        print(f\"üóëÔ∏è  Frames existantes supprim√©es\")\n",
        "\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"‚ùå Impossible d'ouvrir la vid√©o: {video_path}\")\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    print(f\"üìä Vid√©o: {total_frames} frames, {fps:.1f} FPS\")\n",
        "    print(f\"üìä Frames √† extraire: ~{total_frames // frame_interval}\")\n",
        "\n",
        "    extracted_count = 0\n",
        "    frame_idx = 0\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Extraire seulement selon l'intervalle\n",
        "            if frame_idx % frame_interval == 0:\n",
        "                output_idx = frame_idx // frame_interval\n",
        "                filename = frames_dir / f\"{output_idx:05d}.jpg\"\n",
        "                cv2.imwrite(str(filename), frame, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
        "                extracted_count += 1\n",
        "\n",
        "                if extracted_count % 50 == 0:\n",
        "                    progress = (frame_idx / total_frames) * 100\n",
        "                    print(f\"üìä Progr√®s: {extracted_count} frames extraites ({progress:.1f}%)\")\n",
        "\n",
        "            frame_idx += 1\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "\n",
        "    print(f\"‚úÖ {extracted_count} frames extraites\")\n",
        "    return extracted_count\n",
        "\n",
        "def count_existing_frames(frames_dir: Path) -> int:\n",
        "    \"\"\"Compte les frames existantes dans le dossier\"\"\"\n",
        "    existing_frames = list(frames_dir.glob(\"*.jpg\"))\n",
        "    return len(existing_frames)\n",
        "\n",
        "def extract_frames_with_config(cfg) -> int:\n",
        "    \"\"\"Extrait les frames en utilisant la configuration centralis√©e\"\"\"\n",
        "    \n",
        "    # V√©rification des fichiers (gestion Colab/Local)\n",
        "    if cfg.USING_COLAB and not cfg.video_path.exists():\n",
        "        print(\"üî¨ Mode Colab: Vid√©o pas encore upload√©e\")\n",
        "        print(f\"   üí° Uploadez {cfg.video_path.name} dans {cfg.videos_dir}\")\n",
        "        print(f\"   üí° Puis relancez cette cellule ou utilisez cfg.wait_for_files()\")\n",
        "        return 0\n",
        "    \n",
        "    # Extraction selon configuration\n",
        "    if cfg.EXTRACT_FRAMES:\n",
        "        return extract_frames(\n",
        "            video_path=cfg.video_path,\n",
        "            frames_dir=cfg.frames_dir,\n",
        "            frame_interval=cfg.FRAME_INTERVAL,\n",
        "            force_extraction=cfg.FORCE_EXTRACTION\n",
        "        )\n",
        "    else:\n",
        "        # Skip extraction - compter les frames existantes\n",
        "        existing_count = count_existing_frames(cfg.frames_dir)\n",
        "        \n",
        "        print(f\"‚è≠Ô∏è  Extraction d√©sactiv√©e (cfg.EXTRACT_FRAMES = False)\")\n",
        "        if existing_count > 0:\n",
        "            print(f\"üìÇ Utilisation de {existing_count} frames existantes\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  Aucune frame trouv√©e dans {cfg.frames_dir}\")\n",
        "            print(f\"üí° Conseil: Activez cfg.EXTRACT_FRAMES = True pour extraire\")\n",
        "        \n",
        "        return existing_count\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ EXTRACTION AVEC CONFIGURATION CENTRALIS√âE\n",
        "# =============================================================================\n",
        "\n",
        "# Extraction intelligente selon l'environnement\n",
        "print(\"üé¨ D√©marrage de l'extraction des frames...\")\n",
        "\n",
        "# V√©rification pr√©requis selon l'environnement\n",
        "if cfg.USING_COLAB:\n",
        "    print(\"üî¨ Mode Colab: V√©rification des fichiers upload√©s...\")\n",
        "    if not cfg.video_path.exists():\n",
        "        print(f\"‚ö†Ô∏è  Vid√©o pas encore upload√©e: {cfg.video_path.name}\")\n",
        "        print(f\"   üì§ Uploadez dans: {cfg.videos_dir}\")\n",
        "        print(f\"   üîÑ Puis relancez cette cellule\")\n",
        "        extracted_frames_count = 0\n",
        "    else:\n",
        "        extracted_frames_count = extract_frames_with_config(cfg)\n",
        "else:\n",
        "    print(\"üñ•Ô∏è Mode Local: Extraction directe\")\n",
        "    extracted_frames_count = extract_frames_with_config(cfg)\n",
        "\n",
        "# Ajout du r√©sultat √† la configuration pour usage ult√©rieur\n",
        "cfg.extracted_frames_count = extracted_frames_count\n",
        "\n",
        "print(f\"\\nüìä R√âSUM√â EXTRACTION:\")\n",
        "print(f\"   üé¨ Frames extraites/compt√©es: {extracted_frames_count}\")\n",
        "print(f\"   üìÅ Dossier: {cfg.frames_dir}\")\n",
        "print(f\"   ‚úÖ cfg.extracted_frames_count = {extracted_frames_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ü§ñ INITIALISATION SAM2\n",
        "# =============================================================================\n",
        "\n",
        "def initialize_sam2_predictor(cfg, verbose=True):\n",
        "    \"\"\"Initialise le predictor SAM2 avec la configuration centralis√©e\"\"\"\n",
        "    \n",
        "    # Import SAM2\n",
        "    from sam2.build_sam import build_sam2_video_predictor\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"ü§ñ Initialisation SAM2...\")\n",
        "        print(f\"   üß† Mod√®le: {cfg.model_config_path}\")\n",
        "        print(f\"   üíæ Checkpoint: {cfg.checkpoint_path}\")\n",
        "        print(f\"   üñ•Ô∏è  Device: {cfg.device}\")\n",
        "    \n",
        "    # V√©rification du checkpoint\n",
        "    if not cfg.checkpoint_path.exists():\n",
        "        raise FileNotFoundError(f\"‚ùå Checkpoint SAM2 non trouv√©: {cfg.checkpoint_path}\")\n",
        "    \n",
        "    # Construction du predictor\n",
        "    predictor = build_sam2_video_predictor(\n",
        "        config_file=cfg.model_config_path,\n",
        "        ckpt_path=str(cfg.checkpoint_path),\n",
        "        device=cfg.device\n",
        "    )\n",
        "    \n",
        "    return predictor\n",
        "\n",
        "def initialize_inference_state(predictor, cfg, verbose=True):\n",
        "    \"\"\"Initialise l'√©tat d'inf√©rence avec v√©rifications\"\"\"\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\nüé¨ Initialisation √©tat d'inf√©rence...\")\n",
        "        print(f\"   üìÅ Frames: {cfg.frames_dir}\")\n",
        "    \n",
        "    # V√©rification des frames\n",
        "    if cfg.extracted_frames_count == 0:\n",
        "        raise ValueError(f\"‚ùå Aucune frame extraite. Extrayez d'abord les frames.\")\n",
        "    \n",
        "    # Initialisation de l'√©tat d'inf√©rence\n",
        "    inference_state = predictor.init_state(\n",
        "        video_path=str(cfg.frames_dir),\n",
        "        offload_video_to_cpu=True,    # √âconomise la m√©moire GPU\n",
        "        offload_state_to_cpu=False    # Garde l'√©tat en GPU\n",
        "    )\n",
        "    \n",
        "    # Reset de l'√©tat\n",
        "    predictor.reset_state(inference_state)\n",
        "    \n",
        "    # V√©rification\n",
        "    loaded_frames = inference_state[\"num_frames\"]\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n‚úÖ SAM2 initialis√©:\")\n",
        "        print(f\"   üñºÔ∏è  Frames extraites: {cfg.extracted_frames_count}\")\n",
        "        print(f\"   üé¨ Frames charg√©es: {loaded_frames}\")\n",
        "        print(f\"   ‚úÖ Correspondance: {'OK' if cfg.extracted_frames_count == loaded_frames else 'ERREUR'}\")\n",
        "        \n",
        "        if cfg.device.type == \"cuda\":\n",
        "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "            print(f\"   üíæ GPU Memory: {allocated:.2f}GB\")\n",
        "    \n",
        "    if cfg.extracted_frames_count != loaded_frames:\n",
        "        print(f\"‚ö†Ô∏è Incoh√©rence frames : {cfg.extracted_frames_count} extraites vs {loaded_frames} charg√©es\")\n",
        "    \n",
        "    return inference_state\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ INITIALISATION AVEC CONFIGURATION CENTRALIS√âE\n",
        "# =============================================================================\n",
        "\n",
        "# V√©rification pr√©requis\n",
        "if not hasattr(cfg, 'extracted_frames_count') or cfg.extracted_frames_count == 0:\n",
        "    print(\"‚ùå Frames non extraites. Ex√©cutez d'abord la cellule d'extraction des frames.\")\n",
        "    print(\"üí° Ou d√©finissez cfg.extracted_frames_count manuellement si frames d√©j√† pr√©sentes\")\n",
        "else:\n",
        "    # Initialisation SAM2\n",
        "    predictor = initialize_sam2_predictor(cfg)\n",
        "    inference_state = initialize_inference_state(predictor, cfg)\n",
        "    \n",
        "    # Ajout √† la configuration pour usage ult√©rieur\n",
        "    cfg.predictor = predictor\n",
        "    cfg.inference_state = inference_state\n",
        "    \n",
        "    print(\"\\n‚úÖ SAM2 pr√™t pour l'ajout d'annotations!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üéØ AJOUT DES ANNOTATIONS INITIALES\n",
        "# =============================================================================\n",
        "\n",
        "def add_initial_annotations(predictor, inference_state, project_config: Dict[str, Any]):\n",
        "    \"\"\"Ajoute les annotations initiales depuis la configuration projet.\"\"\"\n",
        "\n",
        "    print(f\"üéØ Ajout des annotations initiales...\")\n",
        "\n",
        "    # Cr√©ation du mapping obj_id -> obj_type\n",
        "    obj_types = {}\n",
        "    for obj in project_config['objects']:\n",
        "        obj_types[obj['obj_id']] = obj['obj_type']\n",
        "\n",
        "    # Extraction automatique des annotations et frames depuis le JSON\n",
        "    all_annotations = []\n",
        "    annotation_frames = []\n",
        "\n",
        "    for frame_data in project_config['initial_annotations']:\n",
        "        frame_idx = frame_data['frame']\n",
        "        annotations = frame_data['annotations']\n",
        "        annotation_frames.append(frame_idx)\n",
        "\n",
        "        print(f\"   üìç Frame {frame_idx}: {len(annotations)} annotations\")\n",
        "\n",
        "        for annotation in annotations:\n",
        "            all_annotations.append({\n",
        "                'frame': frame_idx,\n",
        "                'obj_id': annotation['obj_id'],\n",
        "                'points': annotation['points'],\n",
        "                'obj_type': obj_types.get(annotation['obj_id'], f'unknown_{annotation[\"obj_id\"]}')\n",
        "            })\n",
        "\n",
        "    if not all_annotations:\n",
        "        raise ValueError(f\"‚ùå Aucune annotation trouv√©e dans le fichier config\")\n",
        "\n",
        "    print(f\"   üìä Total: {len(all_annotations)} annotations sur {len(set(annotation_frames))} frames\")\n",
        "\n",
        "    # Ajout des annotations √† SAM2\n",
        "    added_objects = []\n",
        "\n",
        "    for annotation_data in all_annotations:\n",
        "        frame_idx = annotation_data['frame']\n",
        "        obj_id = annotation_data['obj_id']\n",
        "        obj_type = annotation_data['obj_type']\n",
        "        points_data = annotation_data['points']\n",
        "\n",
        "        # Extraction des coordonn√©es et labels\n",
        "        points = np.array([[p['x'], p['y']] for p in points_data], dtype=np.float32)\n",
        "        labels = np.array([p['label'] for p in points_data], dtype=np.int32)\n",
        "\n",
        "        print(f\"   üéØ Frame {frame_idx} - Objet {obj_id} ({obj_type}): {len(points)} points √† ({points[0][0]:.0f}, {points[0][1]:.0f})\")\n",
        "\n",
        "        # Ajout √† SAM2 avec add_new_points_or_box\n",
        "        _, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
        "            inference_state,\n",
        "            frame_idx,\n",
        "            obj_id,\n",
        "            points,\n",
        "            labels\n",
        "        )\n",
        "\n",
        "        # √âviter les doublons dans added_objects\n",
        "        if not any(obj['obj_id'] == obj_id for obj in added_objects):\n",
        "            added_objects.append({\n",
        "                'obj_id': obj_id,\n",
        "                'obj_type': obj_type,\n",
        "                'points_count': len(points)\n",
        "            })\n",
        "\n",
        "    # V√©rification\n",
        "    sam_obj_ids = inference_state[\"obj_ids\"]\n",
        "\n",
        "    print(f\"\\nüìä R√âSUM√â ANNOTATIONS:\")\n",
        "    print(f\"   üéØ Annotations configur√©es: {len(all_annotations)}\")\n",
        "    print(f\"   üéØ Objets uniques: {len(added_objects)}\")\n",
        "    print(f\"   ‚úÖ Objets ajout√©s √† SAM2: {len(sam_obj_ids)}\")\n",
        "    print(f\"   üÜî IDs: {sorted(sam_obj_ids)}\")\n",
        "    print(f\"   üìç Frames utilis√©es: {sorted(set(annotation_frames))}\")\n",
        "\n",
        "    # R√©sum√© par type\n",
        "    type_counts = {}\n",
        "    for obj in added_objects:\n",
        "        obj_type = obj['obj_type']\n",
        "        type_counts[obj_type] = type_counts.get(obj_type, 0) + 1\n",
        "    print(f\"   üè∑Ô∏è  Types: {dict(type_counts)}\")\n",
        "\n",
        "    return added_objects, all_annotations\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ AJOUT AVEC CONFIGURATION CENTRALIS√âE\n",
        "# =============================================================================\n",
        "\n",
        "# V√©rifications pr√©requis\n",
        "if not hasattr(cfg, 'predictor') or not hasattr(cfg, 'inference_state'):\n",
        "    print(\"‚ùå SAM2 non initialis√©. Ex√©cutez d'abord la cellule d'initialisation SAM2.\")\n",
        "elif project_config is None:\n",
        "    print(\"‚ùå Configuration projet non charg√©e.\")\n",
        "    if cfg.USING_COLAB:\n",
        "        print(\"üí° Sur Colab, utilisez: project_config = wait_and_load_config(cfg)\")\n",
        "    else:\n",
        "        print(\"üí° La configuration devrait √™tre charg√©e automatiquement\")\n",
        "else:\n",
        "    # Ajout des annotations\n",
        "    added_objects, initial_annotations_data = add_initial_annotations(\n",
        "        cfg.predictor, \n",
        "        cfg.inference_state, \n",
        "        project_config\n",
        "    )\n",
        "    \n",
        "    # Ajout √† la configuration pour usage ult√©rieur\n",
        "    cfg.added_objects = added_objects\n",
        "    cfg.initial_annotations_data = initial_annotations_data\n",
        "    \n",
        "    print(\"\\n‚úÖ Annotations initiales ajout√©es avec succ√®s!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üîß FONCTIONS UTILITAIRES POUR ANNOTATIONS COMPL√àTES\n",
        "# =============================================================================\n",
        "\n",
        "def get_object_scores(predictor, inference_state, frame_idx, obj_id):\n",
        "    \"\"\"R√©cup√®re les scores d'objet de mani√®re propre et s√ªre\"\"\"\n",
        "    try:\n",
        "        obj_idx = predictor._obj_id_to_idx(inference_state, obj_id)\n",
        "        obj_output_dict = inference_state[\"output_dict_per_obj\"][obj_idx]\n",
        "        temp_output_dict = inference_state[\"temp_output_dict_per_obj\"][obj_idx]\n",
        "\n",
        "        # Chercher dans les outputs\n",
        "        frame_output = None\n",
        "        if frame_idx in temp_output_dict[\"cond_frame_outputs\"]:\n",
        "            frame_output = temp_output_dict[\"cond_frame_outputs\"][frame_idx]\n",
        "        elif frame_idx in temp_output_dict[\"non_cond_frame_outputs\"]:\n",
        "            frame_output = temp_output_dict[\"non_cond_frame_outputs\"][frame_idx]\n",
        "        elif frame_idx in obj_output_dict[\"cond_frame_outputs\"]:\n",
        "            frame_output = obj_output_dict[\"cond_frame_outputs\"][frame_idx]\n",
        "        elif frame_idx in obj_output_dict[\"non_cond_frame_outputs\"]:\n",
        "            frame_output = obj_output_dict[\"non_cond_frame_outputs\"][frame_idx]\n",
        "\n",
        "        if frame_output and \"object_score_logits\" in frame_output:\n",
        "            object_score_logits = frame_output[\"object_score_logits\"]\n",
        "            return torch.sigmoid(object_score_logits).item()\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def calculate_bbox_from_rle(rle_data: Dict[str, Any]) -> Optional[Dict[str, int]]:\n",
        "    \"\"\"Calcule la bounding box depuis un RLE base64.\"\"\"\n",
        "    from pycocotools.mask import toBbox\n",
        "\n",
        "    try:\n",
        "        rle = {\n",
        "            \"size\": rle_data[\"size\"],\n",
        "            \"counts\": base64.b64decode(rle_data[\"counts\"])\n",
        "        }\n",
        "\n",
        "        bbox = toBbox(rle)\n",
        "\n",
        "        result = {\n",
        "            \"x\": int(bbox[0]),\n",
        "            \"y\": int(bbox[1]),\n",
        "            \"width\": int(bbox[2]),\n",
        "            \"height\": int(bbox[3])\n",
        "        }\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erreur calcul bbox: {e}\")\n",
        "        return None\n",
        "\n",
        "def image_to_world(point_2d, cam_params):\n",
        "    \"\"\"\n",
        "    Projette un point 2D de l'image vers le plan du terrain (Z=0).\n",
        "    \"\"\"\n",
        "    # Create projection matrix P\n",
        "    K = np.array([\n",
        "        [cam_params[\"cam_params\"][\"x_focal_length\"], 0, cam_params[\"cam_params\"][\"principal_point\"][0]],\n",
        "        [0, cam_params[\"cam_params\"][\"y_focal_length\"], cam_params[\"cam_params\"][\"principal_point\"][1]],\n",
        "        [0, 0, 1]\n",
        "    ])\n",
        "    R = np.array(cam_params[\"cam_params\"][\"rotation_matrix\"])\n",
        "    t = -R @ np.array(cam_params[\"cam_params\"][\"position_meters\"])\n",
        "    P = K @ np.hstack((R, t.reshape(-1,1)))\n",
        "\n",
        "    # Create point on image plane in homogeneous coordinates\n",
        "    point_2d_h = np.array([point_2d[0], point_2d[1], 1])\n",
        "\n",
        "    # Back-project ray from camera\n",
        "    ray = np.linalg.inv(K) @ point_2d_h\n",
        "    ray = R.T @ ray\n",
        "\n",
        "    # Find intersection with Z=0 plane\n",
        "    camera_pos = np.array(cam_params[\"cam_params\"][\"position_meters\"])\n",
        "    t = -camera_pos[2] / ray[2]\n",
        "    world_point = camera_pos + t * ray\n",
        "\n",
        "    return world_point[:2]  # Return only X,Y coordinates since Z=0\n",
        "\n",
        "def calculate_points_output(bbox_output: dict, cam_params: dict = None) -> dict:\n",
        "    \"\"\"\n",
        "    Calcule les points de sortie √† partir de la bbox output.\n",
        "\n",
        "    Args:\n",
        "        bbox_output: Dict avec 'x', 'y', 'width', 'height'\n",
        "        cam_params: Param√®tres de calibration cam√©ra pour projection terrain\n",
        "\n",
        "    Returns:\n",
        "        Dict avec les points calcul√©s s√©par√©s par plan (image vs field)\n",
        "    \"\"\"\n",
        "    if not bbox_output:\n",
        "        return None\n",
        "\n",
        "    # Calculer le point CENTER_BOTTOM dans le plan image\n",
        "    center_bottom_x = bbox_output['x'] + bbox_output['width'] / 2\n",
        "    center_bottom_y = bbox_output['y'] + bbox_output['height']  # Bas de la bbox\n",
        "\n",
        "    # Structure avec s√©paration image/field\n",
        "    points_output = {\n",
        "        \"image\": {\n",
        "            \"CENTER_BOTTOM\": {\n",
        "                \"x\": float(center_bottom_x),\n",
        "                \"y\": float(center_bottom_y)\n",
        "            }\n",
        "        },\n",
        "        \"field\": {\n",
        "            \"CENTER_BOTTOM\": None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Projection vers le terrain si les param√®tres cam√©ra sont fournis\n",
        "    if cam_params:\n",
        "        try:\n",
        "            # Projeter le point CENTER_BOTTOM vers le terrain\n",
        "            image_point = [center_bottom_x, center_bottom_y]\n",
        "            field_point = image_to_world(image_point, cam_params)\n",
        "\n",
        "            points_output[\"field\"][\"CENTER_BOTTOM\"] = {\n",
        "                \"x\": float(field_point[0]),\n",
        "                \"y\": float(field_point[1])\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erreur projection terrain: {e}\")\n",
        "            points_output[\"field\"][\"CENTER_BOTTOM\"] = None\n",
        "\n",
        "    return points_output\n",
        "\n",
        "def create_mask_annotation(obj_id: int, mask_logits, predictor=None, inference_state=None,\n",
        "                         frame_idx=None, cam_params: Dict = None) -> Dict:\n",
        "    \"\"\"\n",
        "    Cr√©e une annotation de masque compl√®te avec points input/output, bbox et scores.\n",
        "    \"\"\"\n",
        "    # Conversion en masque binaire\n",
        "    mask = (mask_logits > 0.0).cpu().numpy()\n",
        "    if mask.ndim == 3 and mask.shape[0] == 1:\n",
        "        mask = np.squeeze(mask, axis=0)\n",
        "\n",
        "    # Encodage RLE\n",
        "    if not mask.flags['F_CONTIGUOUS']:\n",
        "        mask = np.asfortranarray(mask)\n",
        "\n",
        "    rle = encode_rle(mask.astype(np.uint8))\n",
        "    base64_counts = base64.b64encode(rle[\"counts\"]).decode('ascii')\n",
        "\n",
        "    # Calcul bbox et points output si masque non vide\n",
        "    bbox_output = None\n",
        "    points_output = None\n",
        "\n",
        "    if mask.sum() > 0:\n",
        "        from pycocotools.mask import toBbox\n",
        "        bbox = toBbox(rle)\n",
        "        bbox_output = {\n",
        "            \"x\": int(bbox[0]),\n",
        "            \"y\": int(bbox[1]),\n",
        "            \"width\": int(bbox[2]),\n",
        "            \"height\": int(bbox[3])\n",
        "        }\n",
        "        # Calcul des points output depuis la bbox\n",
        "        points_output = calculate_points_output(bbox_output, cam_params)\n",
        "\n",
        "    # R√©cup√©ration du score du masque\n",
        "    mask_score = None\n",
        "\n",
        "    if predictor and inference_state and frame_idx is not None:\n",
        "        # Score du masque\n",
        "        mask_score = get_object_scores(predictor, inference_state, frame_idx, obj_id)\n",
        "\n",
        "    # Structure d'annotation compl√®te\n",
        "    return {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"objectId\": str(obj_id),\n",
        "        \"type\": \"mask\",\n",
        "        \"mask\": {\n",
        "            \"format\": \"rle_coco_base64\",\n",
        "            \"size\": [int(rle[\"size\"][0]), int(rle[\"size\"][1])],\n",
        "            \"counts\": base64_counts\n",
        "        },\n",
        "        \"bbox\": {\n",
        "            \"output\": bbox_output\n",
        "        },\n",
        "        \"points\": {\n",
        "            \"output\": points_output\n",
        "        },\n",
        "        \"maskScore\": mask_score,\n",
        "        \"pose\": None,\n",
        "        \"warning\": False\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Fonctions utilitaires pour annotations charg√©es!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üîÑ PROPAGATION ET G√âN√âRATION DES ANNOTATIONS\n",
        "# =============================================================================\n",
        "\n",
        "def generate_frame_mapping(total_frames: int, frame_interval: int) -> List[Optional[int]]:\n",
        "    \"\"\"\n",
        "    G√©n√®re le mapping entre frames originales et frames trait√©es.\n",
        "    \n",
        "    Args:\n",
        "        total_frames: Nombre total de frames dans la vid√©o originale\n",
        "        frame_interval: Intervalle entre frames (ex: 10 = 1 frame sur 10)\n",
        "    \n",
        "    Returns:\n",
        "        Liste o√π l'index = frame originale, valeur = frame trait√©e (ou None si pas trait√©e)\n",
        "    \"\"\"\n",
        "    frame_mapping = [None] * total_frames\n",
        "    processed_idx = 0\n",
        "\n",
        "    for original_idx in range(total_frames):\n",
        "        if original_idx % frame_interval == 0:\n",
        "            frame_mapping[original_idx] = processed_idx\n",
        "            processed_idx += 1\n",
        "\n",
        "    return frame_mapping\n",
        "\n",
        "def get_video_info(video_path: Path) -> Dict[str, Any]:\n",
        "    \"\"\"R√©cup√®re les informations de la vid√©o\"\"\"\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"‚ùå Impossible d'ouvrir la vid√©o: {video_path}\")\n",
        "    \n",
        "    video_info = {\n",
        "        'total_frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "        'fps': cap.get(cv2.CAP_PROP_FPS),\n",
        "        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    }\n",
        "    cap.release()\n",
        "    return video_info\n",
        "\n",
        "def create_project_structure_with_config(cfg, project_config: Dict[str, Any], added_objects: List[Dict]) -> Dict[str, Any]:\n",
        "    \"\"\"Cr√©e la structure JSON du projet avec la configuration centralis√©e.\"\"\"\n",
        "    \n",
        "    # Informations vid√©o\n",
        "    video_info = get_video_info(cfg.video_path)\n",
        "    \n",
        "    # Calcul du frame mapping\n",
        "    frame_mapping = generate_frame_mapping(video_info['total_frames'], cfg.FRAME_INTERVAL)\n",
        "    processed_frame_count = sum(x is not None for x in frame_mapping)\n",
        "\n",
        "    # Structure objects avec couleurs\n",
        "    import random\n",
        "    import colorsys\n",
        "\n",
        "    config_objects_mapping = {}\n",
        "    for obj in project_config['objects']:\n",
        "        config_objects_mapping[obj['obj_id']] = obj\n",
        "\n",
        "    objects = {}\n",
        "    for obj_data in added_objects:\n",
        "        obj_id = str(obj_data['obj_id'])\n",
        "        obj_type = obj_data['obj_type']\n",
        "\n",
        "        # R√©cup√©rer les informations compl√®tes depuis le config\n",
        "        config_obj = config_objects_mapping.get(int(obj_id), {})\n",
        "\n",
        "        # Couleur al√©atoire reproductible\n",
        "        random.seed(int(obj_id) * 12345)\n",
        "        hue = random.random()\n",
        "        rgb = colorsys.hsv_to_rgb(hue, 0.8, 0.9)\n",
        "        hex_color = \"#{:02x}{:02x}{:02x}\".format(\n",
        "            int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)\n",
        "        )\n",
        "\n",
        "        objects[obj_id] = {\n",
        "            \"id\": obj_id,\n",
        "            \"type\": obj_type,\n",
        "            \"team\": config_obj.get('team', None),\n",
        "            \"jersey_number\": config_obj.get('jersey_number', None),\n",
        "            \"jersey_color\": config_obj.get('jersey_color', None),\n",
        "            \"role\": config_obj.get('role', None),\n",
        "            \"display_color\": hex_color\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"format_version\": \"1.0\",\n",
        "        \"video\": f\"{cfg.VIDEO_NAME}.mp4\",\n",
        "        \"metadata\": {\n",
        "            \"project_id\": str(uuid.uuid4()),\n",
        "            \"created_at\": datetime.now().isoformat() + \"Z\",\n",
        "            \"fps\": video_info['fps'],\n",
        "            \"resolution\": {\n",
        "                \"width\": video_info['width'],\n",
        "                \"height\": video_info['height'],\n",
        "                \"aspect_ratio\": round(video_info['width'] / video_info['height'], 2)\n",
        "            },\n",
        "            \"frame_interval\": cfg.FRAME_INTERVAL,\n",
        "            \"frame_count_original\": video_info['total_frames'],\n",
        "            \"frame_count_processed\": processed_frame_count,\n",
        "            \"frame_mapping\": frame_mapping,\n",
        "            \"static_video\": False\n",
        "        },\n",
        "        \"calibration\": project_config['calibration'],\n",
        "        \"objects\": objects,\n",
        "        \"initial_annotations\": project_config['initial_annotations'],\n",
        "        \"annotations\": {}\n",
        "    }\n",
        "\n",
        "def run_sam2_propagation(cfg, project_config):\n",
        "    \"\"\"Ex√©cute la propagation SAM2 et g√©n√®re toutes les annotations\"\"\"\n",
        "    \n",
        "    print(f\"üîÑ D√©marrage de la propagation...\")\n",
        "    print(f\"   üé¨ {cfg.extracted_frames_count} frames √† traiter\")\n",
        "    print(f\"   üéØ {len(cfg.added_objects)} objets √† suivre\")\n",
        "\n",
        "    # Cr√©ation de la structure du projet\n",
        "    project = create_project_structure_with_config(cfg, project_config, cfg.added_objects)\n",
        "\n",
        "    # Propagation et annotation\n",
        "    frame_count = 0\n",
        "    for out_frame_idx, out_obj_ids, out_mask_logits in cfg.predictor.propagate_in_video(cfg.inference_state):\n",
        "\n",
        "        if str(out_frame_idx) not in project['annotations']:\n",
        "            project['annotations'][str(out_frame_idx)] = []\n",
        "\n",
        "        for i, out_obj_id in enumerate(out_obj_ids):\n",
        "            annotation = create_mask_annotation(\n",
        "                obj_id=out_obj_id,\n",
        "                mask_logits=out_mask_logits[i],\n",
        "                predictor=cfg.predictor,\n",
        "                inference_state=cfg.inference_state,\n",
        "                frame_idx=out_frame_idx,\n",
        "                cam_params=project_config['calibration']['camera_parameters']\n",
        "            )\n",
        "            project['annotations'][str(out_frame_idx)].append(annotation)\n",
        "        \n",
        "        frame_count += 1\n",
        "        if frame_count % 50 == 0:\n",
        "            progress = (frame_count / cfg.extracted_frames_count) * 100\n",
        "            print(f\"   üìä Progr√®s: {frame_count}/{cfg.extracted_frames_count} frames ({progress:.1f}%)\")\n",
        "    \n",
        "    print(f\"‚úÖ Propagation termin√©e: {frame_count} frames trait√©es\")\n",
        "    return project\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ EX√âCUTION DE LA PROPAGATION\n",
        "# =============================================================================\n",
        "\n",
        "# V√©rifications des pr√©requis\n",
        "missing_requirements = []\n",
        "required_attrs = ['predictor', 'inference_state', 'added_objects', 'extracted_frames_count']\n",
        "\n",
        "for attr in required_attrs:\n",
        "    if not hasattr(cfg, attr):\n",
        "        missing_requirements.append(attr)\n",
        "\n",
        "if project_config is None:\n",
        "    missing_requirements.append(\"project_config\")\n",
        "\n",
        "if missing_requirements:\n",
        "    print(f\"‚ùå Pr√©requis manquants: {missing_requirements}\")\n",
        "    print(\"üí° Ex√©cutez d'abord les cellules pr√©c√©dentes dans l'ordre:\")\n",
        "    print(\"   1. Configuration centralis√©e\")\n",
        "    print(\"   2. Installation SAM2\") \n",
        "    print(\"   3. Chargement configuration projet\")\n",
        "    print(\"   4. Extraction des frames\")\n",
        "    print(\"   5. Initialisation SAM2\")\n",
        "    print(\"   6. Ajout des annotations initiales\")\n",
        "else:\n",
        "    # Ex√©cution de la propagation\n",
        "    project = run_sam2_propagation(cfg, project_config)\n",
        "    \n",
        "    # Ajout √† la configuration pour usage ult√©rieur\n",
        "    cfg.project = project\n",
        "    \n",
        "    # Statistiques finales\n",
        "    total_annotations = sum(len(annotations) for annotations in project['annotations'].values())\n",
        "    unique_frames = len(project['annotations'])\n",
        "    \n",
        "    print(f\"\\nüìä R√âSULTATS PROPAGATION:\")\n",
        "    print(f\"   üé¨ Frames originales: {project['metadata']['frame_count_original']}\")\n",
        "    print(f\"   üé¨ Frames trait√©es: {project['metadata']['frame_count_processed']}\")\n",
        "    print(f\"   üìç Frames avec annotations: {unique_frames}\")\n",
        "    print(f\"   üìç Annotations totales: {total_annotations}\")\n",
        "    print(f\"   üéØ Objets suivis: {len(project['objects'])}\")\n",
        "    print(f\"   ‚èØÔ∏è  Intervalle frames: {project['metadata']['frame_interval']}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Propagation termin√©e avec succ√®s!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHlhY4X5Adf3"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üíæ SAUVEGARDE DES R√âSULTATS\n",
        "# =============================================================================\n",
        "\n",
        "def save_project_results(cfg, project, verbose=True):\n",
        "    \"\"\"Sauvegarde les r√©sultats du projet avec gestion d'erreurs\"\"\"\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"üíæ Sauvegarde des r√©sultats...\")\n",
        "        print(f\"   üìÑ Fichier JSON: {cfg.output_json_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Sauvegarde du JSON principal\n",
        "        with open(cfg.output_json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(project, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"‚úÖ Fichier JSON sauv√©: {cfg.output_json_path}\")\n",
        "            \n",
        "        # Sauvegarde d'une version compacte (sans indent pour √©conomiser l'espace)\n",
        "        compact_json_path = cfg.output_dir / f\"{cfg.VIDEO_NAME}_project_compact.json\"\n",
        "        with open(compact_json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(project, f, separators=(',', ':'), ensure_ascii=False)\n",
        "        \n",
        "        if verbose:\n",
        "            # Tailles des fichiers\n",
        "            json_size = cfg.output_json_path.stat().st_size / 1024**2  # MB\n",
        "            compact_size = compact_json_path.stat().st_size / 1024**2  # MB\n",
        "            print(f\"   üìÑ Version format√©e: {json_size:.1f}MB\")\n",
        "            print(f\"   üìÑ Version compacte: {compact_size:.1f}MB\")\n",
        "            \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur lors de la sauvegarde: {e}\")\n",
        "        return False\n",
        "\n",
        "def display_final_statistics(cfg, project):\n",
        "    \"\"\"Affiche les statistiques finales du projet\"\"\"\n",
        "    \n",
        "    # Calcul des statistiques\n",
        "    total_annotations = sum(len(annotations) for annotations in project['annotations'].values())\n",
        "    unique_frames = len(project['annotations'])\n",
        "    \n",
        "    # Calcul de la taille des donn√©es\n",
        "    json_size = cfg.output_json_path.stat().st_size / 1024**2 if cfg.output_json_path.exists() else 0\n",
        "    \n",
        "    print(f\"\\nüìä R√âSULTATS FINAUX:\")\n",
        "    print(f\"   üé¨ Frames originales: {project['metadata']['frame_count_original']:,}\")\n",
        "    print(f\"   üé¨ Frames trait√©es: {project['metadata']['frame_count_processed']:,}\")\n",
        "    print(f\"   üìç Frames avec annotations: {unique_frames:,}\")\n",
        "    print(f\"   üìç Annotations totales: {total_annotations:,}\")\n",
        "    print(f\"   üéØ Objets suivis: {len(project['objects'])}\")\n",
        "    print(f\"   ‚èØÔ∏è  Intervalle frames: {project['metadata']['frame_interval']}\")\n",
        "    print(f\"   üìÑ Taille JSON: {json_size:.1f}MB\")\n",
        "    print(f\"   üìÅ Dossier de sortie: {cfg.output_dir}\")\n",
        "    \n",
        "    # Affichage d'un √©chantillon du mapping\n",
        "    sample_mapping = [(i, v) for i, v in enumerate(project['metadata']['frame_mapping'][:50]) if v is not None]\n",
        "    print(f\"   üóÇÔ∏è  Mapping √©chantillon (original‚Üítrait√©): {sample_mapping[:5]}...\")\n",
        "    \n",
        "    # R√©sum√© par type d'objet\n",
        "    if project['objects']:\n",
        "        type_counts = {}\n",
        "        for obj_data in project['objects'].values():\n",
        "            obj_type = obj_data.get('type', 'unknown')\n",
        "            type_counts[obj_type] = type_counts.get(obj_type, 0) + 1\n",
        "        print(f\"   üè∑Ô∏è  Types d'objets: {dict(type_counts)}\")\n",
        "def create_colab_backup(cfg, use_timestamp=False, custom_suffix=\"\"):\n",
        "    \"\"\"Cr√©e une sauvegarde sur Google Drive pour Colab\"\"\"\n",
        "    \n",
        "    if not cfg.USING_COLAB:\n",
        "        print(\"üñ•Ô∏è Mode local: sauvegarde Google Drive skipp√©e\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        import shutil\n",
        "        from datetime import datetime\n",
        "        \n",
        "        print(\"üî¨ Mode Colab: Cr√©ation de la sauvegarde Google Drive...\")\n",
        "        \n",
        "        # Monter le Drive\n",
        "        print(\"   üìÅ Montage Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "        \n",
        "        # Construction du nom selon les options\n",
        "        if use_timestamp:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            zip_name = f\"{cfg.VIDEO_NAME}_{timestamp}\"\n",
        "        elif custom_suffix:\n",
        "            zip_name = f\"{cfg.VIDEO_NAME}_{custom_suffix}\"\n",
        "        else:\n",
        "            zip_name = cfg.VIDEO_NAME\n",
        "        \n",
        "        drive_zip_path = f'/content/drive/MyDrive/{zip_name}'\n",
        "        \n",
        "        # V√©rifier si le fichier existe d√©j√†\n",
        "        existing_zip = Path(f\"{drive_zip_path}.zip\")\n",
        "        if existing_zip.exists():\n",
        "            existing_size = existing_zip.stat().st_size / 1024**2\n",
        "            print(f\"   üîÑ Fichier existant trouv√©: {zip_name}.zip ({existing_size:.1f}MB) - sera √©cras√©\")\n",
        "        \n",
        "        print(f\"   üì¶ Cr√©ation du ZIP: {zip_name}.zip\")\n",
        "        \n",
        "        # Cr√©er le ZIP avec tout le dossier videos\n",
        "        shutil.make_archive(drive_zip_path, 'zip', str(cfg.videos_dir))\n",
        "        \n",
        "        # V√©rifier la taille\n",
        "        zip_path = Path(f\"{drive_zip_path}.zip\")\n",
        "        if zip_path.exists():\n",
        "            zip_size = zip_path.stat().st_size / 1024**2  # MB\n",
        "            print(f\"‚úÖ Sauvegarde cr√©√©e: {zip_name}.zip ({zip_size:.1f}MB)\")\n",
        "            print(f\"   üìÅ Emplacement: MyDrive/{zip_name}.zip\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ùå Erreur: fichier ZIP non cr√©√©\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur sauvegarde Google Drive: {e}\")\n",
        "        return False\n",
        "\n",
        "def cleanup_temporary_files(cfg):\n",
        "    \"\"\"Nettoie les fichiers temporaires (optionnel)\"\"\"\n",
        "    \n",
        "    print(\"üßπ Nettoyage optionnel...\")\n",
        "    \n",
        "    # Comptage des frames\n",
        "    frame_count = len(list(cfg.frames_dir.glob(\"*.jpg\")))\n",
        "    frame_size = sum(f.stat().st_size for f in cfg.frames_dir.glob(\"*.jpg\")) / 1024**2\n",
        "    \n",
        "    print(f\"   üñºÔ∏è  Frames extraites: {frame_count} fichiers ({frame_size:.1f}MB)\")\n",
        "    print(f\"   üí° Pour lib√©rer l'espace, vous pouvez supprimer: {cfg.frames_dir}\")\n",
        "    print(f\"   üí° Les frames peuvent √™tre r√©-extraites avec FORCE_EXTRACTION=True\")\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ SAUVEGARDE AVEC √âCRASEMENT PAR D√âFAUT\n",
        "# =============================================================================\n",
        "\n",
        "# V√©rification des pr√©requis\n",
        "if not hasattr(cfg, 'project') or cfg.project is None:\n",
        "    print(\"‚ùå Projet non disponible. Ex√©cutez d'abord la propagation.\")\n",
        "else:\n",
        "    print(f\"üíæ D√©marrage de la sauvegarde...\")\n",
        "    \n",
        "    # Sauvegarde principale\n",
        "    save_success = save_project_results(cfg, cfg.project)\n",
        "    \n",
        "    if save_success:\n",
        "        # Affichage des statistiques\n",
        "        display_final_statistics(cfg, cfg.project)\n",
        "        \n",
        "        # Sauvegarde Colab si applicable\n",
        "        if cfg.USING_COLAB:\n",
        "            print(f\"\\nüî¨ Sauvegarde Google Drive...\")\n",
        "            \n",
        "            # Mode par d√©faut : √©crase l'ancienne version\n",
        "            colab_success = create_colab_backup(cfg)  # use_timestamp=False par d√©faut\n",
        "            \n",
        "            # Si vous voulez un timestamp occasionnellement, d√©commentez :\n",
        "            # colab_success = create_colab_backup(cfg, use_timestamp=True)\n",
        "            \n",
        "            if colab_success:\n",
        "                print(\"‚úÖ Sauvegarde Google Drive r√©ussie!\")\n",
        "        \n",
        "        # Nettoyage optionnel\n",
        "        print(f\"\\nüßπ Informations de nettoyage:\")\n",
        "        cleanup_temporary_files(cfg)\n",
        "        \n",
        "        print(f\"\\nüéâ Pipeline SAM2 termin√© avec succ√®s!\")\n",
        "        print(f\"üìÑ Fichier principal: {cfg.output_json_path}\")\n",
        "        if cfg.USING_COLAB:\n",
        "            print(f\"‚òÅÔ∏è Sauvegarde Drive: MyDrive/{cfg.VIDEO_NAME}.zip\")\n",
        "            \n",
        "    else:\n",
        "        print(\"‚ùå √âchec de la sauvegarde\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
